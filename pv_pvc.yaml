>

>What problems does it solve?
    Containers running inside the pod can not share the files with each other.
    All the files inside the container are temporary which means if you terminate the container,
    you are going to lose all your files.( and in case of EmptyDir too)
    Secondly if in any case, your container crashes then there is no way to recover files.
    Kuberenetes provides volume plugin as Persistent Volume to address the above problems.

    The lifecycle of these volumes are independent of the lifecycle of pods. (host path)
    So if PODs are terminated then volumes are unmounted and detached keeping the data intact.

>What is Persistent Volume(PV)?
    In simple terms, it's storage/pool of storage volumes available within your Kubernetes cluster. 
    This storage can be provisioned by you or Kubernetes administrator.

    It's basically a directory with some data in it and all the containers running inside the pods can access it. 
    But Persistent Volumes are independent of the POD life cycle.

    it is a cluster wide resource, used to store /persist data beyond the lifetime of a pod.

    So if PODs live or die, persistent volume does not gets affected and it can be reused by some other PODs.


  >  Kubernetes provides many volume plugins based on the cloud service provider you are using ___
        awsElasticBlockStore, azureDisk, azureFile, cephfs, cinder, configMap, csi, downwardAPI, 
        emptyDir, fc (fibre channel), flexVolume, flocker, gcePersistentDisk, gitRepo (deprecated), 
        glusterfs, hostPath, iscsi, local, nfs, persistentVolumeClaim, projected, portworxVolume, 
        quobyte, rbd, scaleIO, secret, storageos, vsphereVolume


>What is Persistent Volume claim?
    Persistent volume claim provides you an abstraction between the consumption of the storage 
    and implementation of the storage.
    In the nutshell you can say, its a request for storage on behalf of an application which is running on cluster.


>---------------------------------------------------------------------------------------------------------------

>flow :-   POD------>PVC------->PV----->h/w storage

1. create/execute manifest for volume i.e provision the required PV 
2. bind the volume to PVC i.e. execute manifest for pvc 
3. Create the pod and attach the pvc to it. 


>POD_

apiVersion: v1
kind: Pod
metadata:
  name: jhooq-pod-with-pvc
  labels:
    name: jhooq-pod-with-pvc
spec:
  containers:
  - name: jhooq-pod-with-pvc
    image: rahulwagh17/kubernetes:jhooq-k8s-springboot
    ports:
      - containerPort: 8080
        name: www

    volumeMounts:
      - name: www-persistent-storage
        mountPath: /home/vagrant/storage

  volumes:
    - name: www-persistent-storage
      persistentVolumeClaim:
        claimName: jhooq-pvc   # name of the pvc

>PVC_

apiVersion: v1
kind: PersistentVolumeClaim
metadata:
  name: jhooq-pvc        # name will be referenced by storage claiming pod
spec:
  volumeName: jhooq-demo-pv           # name of the pv
  storageClassName: local-storage     # must need to same as describe in PV specs, it will decide which PV 
  volumeMode: Filesystem              # will get served the claim.
  accessModes:
    - ReadWriteOnce
  resources:
    requests:
      storage: 1Gi   # 1gib out of 10gib provisioned by pv.


>PV_

apiVersion: v1
kind: PersistentVolume
metadata:
  name: jhooq-demo-pv         # name will be referenced by pvc

spec:
  capacity:
    storage: 10Gi
  volumeMode: Filesystem       #filesystem or Block
  accessModes:
  - ReadWriteOnce
  persistentVolumeReclaimPolicy: Retain     #other, Delete
  storageClassName: local-storage           # or Manual, if cluster is not provisned on cloud 
  local:                                    #or-->  hostPath:
    path: /home/vagrant/storage             #          path: "/path"

  nodeAffinity:
    required:
      nodeSelectorTerms:
      - matchExpressions:
        - key: kubernetes.io/hostname   # pv will be provisioned on the node with given key as a label attached to it
          operator: In
          values:
          - node1


>kubectl get pv
>kubectl get pvc
>kubectl describe pv <pv_name>
>kubectl describe pvc <pvc_name>

>If there are multiple PV's and if we do (not) exclusively mentioned the volumeName in pvc, 
>then k8s will check, what pv will satisfy the storage need as per pvc and automatically those will
>be bind together.


> accessModes, can be_ (from statefulset video)

     ReadWriteOnce (RWO) : only single worker "NODE" can mount the volume for reading and writing at same time.
                           this mode will still allow multiple pods to access the volume when pods are running
                           on same node on which PV is provisioned on.
                           (for pvc, is the only mode supported, if storage class is manual)

     ReadOnlyMany (ROX)  : the volume can be mounted as read-only by many nodes at the same time.
                           (for pvc, do not support if storage class is manual, available only when cluster is 
                           provisioned on cloud)

     ReadWriteMany (RWX) : the volume can be mounted as read-write by many nodes at the same time. 
                           (for pvc, do not support if storage class is manual, available only when cluster is 
                           provisioned on cloud)


>persistentVolumeReclaimPolicy, can be_

  >reclaim policy tell us , what happens to persistent volume , when the PVC is deleted.

     Delete  : it deletes volume content and makes the volume available to be claimed again as 
               soon as pvc gets deleted. 

     Retain  : pv content will be persisted after pvc is deleted and it can not be reused, until
               administrator reclaim the volume manually.

     Recycle : this policy will remove everything from the perticular device. this policy is valid
               only for NFS and HostPath type.           

>--------------------------------------------------------------------------------------------------------------- 


>Pros and Cons_
  After using the persistent volume and persistent volume claim, 
  I must say its always beneficial to use both when you are working in the production environment because
  you can not just delete the data after the end of the POD cycle.

  The most favorable use case which I can see setting up the database such as
  MySQL, Oracle, Postgress inside the persistent volume so that it is always there irrespective 
  of your POD life cycle.

>Pros_
  Storing and archiving the logs
  Setting up the database
  Useful for application handling a large number of batch jobs
  Storing configs of application
  Independent from PODs life-cycle
  Easy to use
  Easy to backup

>Cons_
  Can not be used to store transnational data for performance-intensive application
  You need to set up your own backup policies
  Couldn't be used for HA(High Availability)

>Conclusion_
  If you are reading this part of the blog post then I must say you have at least 
  implemented PV and PVC inside your Kubernetes cluster. But to conclude it here is recap of what we did -

  Gone through the concepts of "What is Persistent Volume and Persistent Volume Claim"
  Then we created a Persistent Volume .i.e - jhooq-demo-pv with 1 Gi of storage
  Created the Persistent Volume Claim .i.e. - jhooq-pvc to use persistent volume jhooq-demo-pv
  Finally created the POD and deployed spring boot microservice.


>---------------------------------------------------------------------------------------------------------------

>Admin creates a pool of persistant volumes/PV's for user to choose from. pv can have varying properties, 
>such a performance for different problems.
>it is a cluster wide resource used to store /persist data beyond the lifetime of a pod.

>pv's are not generally backed by any locally attached storage on worker node but by networked storage system 
>such as cloud providers storage or NFS or distributed filesystem like Ceph or GlusterFS. 

>PV provide a file system that can be mounted on to the cluster, without being associated with any 
>perticular node.

>it act as an abstraction layer to save the user from going in to the details of storage is managed
>and provisioned by each cloud provider. This api object captures the details of the implemantation
>of the storage , be that NFS, iSCSI or cloud provider specific storage system.

>advantage of pv is that, it can be shared not only between pods of single node but 
>among the pods of multiple nodes. this means pv can be scaled by expanding their sizes, However reducing 
>size is not possible.

>Statefulset are the most frequent users of the pv since they need a permanant storage for their pods.


>There are two ways to provisioned the persistant volume_

1> statically  : a cluster admin creates a numbers of pv's , they carry the details of the real storage,
                 which is available for use by cluster users.

2> Dynamically : When none of the admin created pv that matches the users pvc, then the cluster 
                 may try to dynamically provisioned the volume/pv as per users request, specially for the pvc. 
                  
>                 This dynamic provisioning is based on StorageClasses, the pv must request a storage class 
>                 and the admin must have created and configured that class for dynamic provisioning to occure.

>                 to enable dynamic storage provisioning , we have to enable the DefaultStorageClass admission'
>                 controller on the k8s API server.


>-----------------------------------------------------------------------------------------------------------------

Storage Class_ :

>storage class is a k8s object thats let user to specify which type of the storage they need from the 
>cloud provider. it is useful for dynamic provisioning of the PVs.

>Assume , that if the pod requires 10Gi storage capacity and no current PV can match the this PVC requirement,
>the STORAGECLASS automatically creates a PV for this PVC.

>most cloud provider (managed cluster services), provides the default storage class when you set up the
>k8s cluster. 
>To check the default/available storage class within the cluster, we can get this using 
kubectl get storageclass

>different storage class represents various qualities, such as Disk speed like SSD/HDD, and Throughput,
>backup or replication policies. Type of the file system are selected depending on the scenario and the 
>need cloud provider supports.

>Minikube provides default storage class as HostPath type.

>-----------------------------------------------------------------------------------------------------------------

*from_cloud_deeptech_
>Dynamic volume provisioning using storage class.

>Storage Class :-

storage class is used to manage persistance volume. 
storage class will do Dynamic provisioning of storage using cloud provider like aws, gcp etc.

if our cluster is not associated with any cloud provider, we will not be able to storage class. that our claim
will fail.

storage class / pv are not namespaced object. pvc is namespaced.

>ref_ https://kubernetes.io/docs/concepts/storage/storage-classes/


apiVersion: storage.k8s.io/v1
kind: StorageClass
metadata:
  name: k8s-storage-sc

provisioner: kubernetes.io/aws-ebs     # determines what volume plugin is used for provisioning
parameters:
  type: gp2
  iopsPerGB: "10"
  fsType: ext4                         # gp2, aws specific

reclaimPolicy: Retain                  # retain or delete
allowVolumeExpansion: true             # allow dymanic resizing
mountOptions:
  - debug
volumeBindingMode: Immediate           # Immediate or waitForFistConsumer



*volumeBindingMode_

>Immediate,  mode indicates that volume binding and dynamic provisioning occurs once the 
>PersistentVolumeClaim is created

>WaitForFirstConsumer, mode which will delay the binding and provisioning of a PersistentVolume until a
>Pod using the PersistentVolumeClaim is created.


>pv :-

apiVersion: v1
kind: PersistentVolume
metadata:
  name:  k8s-storage-pv 

spec:
  capacity:
    storage: 10Gi
  volumeMode: Filesystem
  accessModes:
  - ReadWriteOnce
  persistentVolumeReclaimPolicy: Retain    #Recycle or delete
  storageClassName: k8s-storage-sc



>pvc :-

apiVersion: v1
kind: PersistentVolumeClaim
metadata:
  name: k8s-storage-pvc

spec:       
  storageClassName: k8s-storage-sc
  volumeMode: Filesystem                       
  accessModes:
    - ReadWriteOnce
  resources:
    requests:
      storage: 1Gi



>POD_

apiVersion: v1
kind: Pod
metadata:
  name: k8s-storage-pod

spec:
  containers:
  - name: k8s-storage-containers
    image: nginx

    volumeMounts:
      - name: k8s-storage-volume
        mountPath: /home/data

  volumes:
    - name: k8s-storage-volume
      persistentVolumeClaim:
        claimName: k8s-storage-pvc


*flow_

>aws ebs ---> StorageClass ---> PV ---> PVC ---> Pod/Deployments ---> Application


>-----------------------------------------------------------------------------------------------------------------