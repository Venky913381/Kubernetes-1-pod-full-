>

>Desired state is the core concept in k8s.
>through declarative or imperative Approch, we describe the desire state of the objects 
>like pod, rs, deployment in the cluster.

>if there are any failures , a pod stops running , the kubelet recreates the pod based on the 
>record of desired state in etcd.

>kubeController managers in the MASTER responsible for the regulating the state of the system. if they
>detects any drift in current state of the cluster, they instruct the KUBELET components in the WORKER
>to spin up the additional pods depends on the desired state. 
>this way k8s ensured that all the containers running across the cluster are always in the desired state.

>we need a controller for our application , for the purpose of Relibility, LoadBalancing, Scalling.

>read: https://kubernetes.io/docs/concepts/workloads/controllers/replicationcontroller/

>replication controller was the original form of the replication in k8s.
>replication controller, was tasked with ensuring high availibilty by replacing unhealthy/dead pods with 
>new ones to ensure required replicas are always up and running inside the cluster.

>we can use rc to control the deployment of single pod also. rc will help by automatically bringing up the
>new pod when the existing one fails.
>Another reason we need replication controller to create multiple pod and share the load across them.

>Replication Controller uses Equality Based Selector(older), while Replica-Set uses Set Based Selector(latest).
>it is like hard selection and not expressive as set based selectors are.

>Replication Controller is now deprecated and is replaced by Replica Set.


apiVersion: v1
kind: ReplicationController

metadata:
  name: rc1            
  labels: 
    controllername: appcontroller

spec:
  replicas: 4
  template:                    # USES ONLY EQUILITY BASED SELECTOR. it is hard selection
    metadata:
      name: servicepod         # by default it will the use containers label to match with rc, 
      labels:                  # if we do not declare, the selector explicitaly
         appname: myapp        # to match with be pods.
    spec: 
      containers:
        - image: coolgourav147/nginx-custom
          imagePullPolicy: Never
          name: contone
          ports: 
          - containerPort: 4545
          - containerPort: 3030


>kubectl apply -f <rc.yaml>                  ---> repeatative usage for declarative object config.
>kubectl get rc  -o-wide / --show-labels

>kubectl delete -f <rc.yaml>
>kubectl delete rc <rcname>

#manual scalling__
>kubectl scale rc --replicas=<n> <rc-name>   ---> imperative command
>kubectl edit rc <rc-name>                   ---> imperative object configuration 
>edit in this yaml file                      ---> declarative object configuration 




apiVersion: v1
kind: ReplicationController

metadata:
  name: rc1            
  labels: 
    controllername: appcontroller

spec:
  replicas: 4
  selector:
    appname: myapp      #explicitaly giving the selector , rc will match to this selector to select existing pods   

  template:
    metadata:
      name: servicepod    
      labels:                  
         appname: myapp 
         type: frontend
    spec: 
      containers:
        - image: coolgourav147/nginx-custom
          imagePullPolicy: Never
          name: contone

# selector value and pods label needed to match,  even if selector is given
# pod label is must. If selector attribute  is not provided
# then pods label is taken as default selector for rc.

>if there are multiple selectors ALL SELECTORS MUST NEEDED TO BR MATCHED.

>--------------------------------------------------------------------------------------------------------------