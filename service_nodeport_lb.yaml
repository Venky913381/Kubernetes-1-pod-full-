>
>Service in k8s

>we need a services for enabling the pod-to-pod communication, also to enable external traffic to access 
>microservice/app deployed in k8s pod.

>services can be defined through yaml manifest files or using imperative command. and can be deployed using 
>kubectl apply -f <service_file.yaml> command.

>Port :- port in service manifest file, represents the actual port that service listen on. if service listens 
>        on port 3000, we can access the service through its <service_name>:3000

>Target Port :- target port represents the actual Container Port of the pod. it should match the container port
>               in the podmanifest file.

>Node Port :- Node port represents the port of the Node , from which external traffic access the service. 
>             It is used with Ip address of the node/ec2 , and serice will be accessible.
>             NodePort Ranges from port 30000 to port 32767.

>type : type represent the type of the service.

>flow :  <ip_address>:NodePort ------>  Port ------> TargetPort   {for nodePort service}

>kubectl get service -l label=value  ---> to get service details filtered by labels.

>--------------------------------------------------------------------------------------------------------------

>NodePort_

>A NodePort service is the most primitive way to get external traffic directly to your service. 
>NodePort, as the name implies, opens a specific port on all the Nodes (the VMs), 
>and any traffic that is sent to this port is forwarded to the service.

apiVersion: v1
kind: Service
metadata:  
  name: my-nodeport-service
spec:
  selector:    
    app: my-app
  type: NodePort
  ports:  
  - name: http
    port: 80
    targetPort: 80
    nodePort: 30036
    protocol: TCP


Basically, a NodePort service has two differences from a normal “ClusterIP” service. 
First, the type is “NodePort.” There is also an additional port called the nodePort that specifies 
which port to open on the nodes. If you don't specify this port, it will pick a random port. 
Most of the time you should let Kubernetes choose the port.

>When would you use this?, There are many downsides to this method:

>1.You can only have one service per port
>2.You can only use ports 30000–32767
>3.If your Node/VM IP address change, you need to deal with that

For these reasons, It is not recommend using this method in production to directly expose your service. 
If you are running a service that doesn't have to be always available, or you are very cost sensitive,
this method will work for you. 


if minikube is running on aws ec2:

>You need to port forward the traffic from your EC2 node to minikube, as minikube itself will
>runs as separate Virtual Machine on ec2.
Once you have kubectl setup on the host machine,to communicate with the minikube cluster, 
you can use kubectl port-forward to forward traffic to any service/pod running inside minikube.

>kubectl port-forward --address 0.0.0.0 svc/<svc-name> <host-port>:<service-port>
>You should be able to access your app at IP:<host-port> as long as the port-forwarding is set up.

>--------------------------------------------------------------------------------------------------------------

>LOAD BALANCER

>we need a cloud environment like eks, gke, aks, civo, platform9 ,digitalOcean etc to use load-balancer type service

>once we sets up our k8s cluster in cloud environment, all we need to do is create a service with
>type as loadBalancer. and this will configure the load balacer provided by cloud provider to our service
>in our cluster.

>A LoadBalancer service is the standard way to expose a service to the internet. 
>On GKE, this will spin up a Network Load Balancer that will give you a single IP address that
>will forward all traffic to your service.

>load balancer service will create a External IP provided by cloud provider, it also exposes the node port
>through which we can access the service. it also provide the clusters internal ip .i.e cluster IP.



apiVersion: v1
kind: Service
metadata:
  name: myapp
  labels: 
    serviceType: Frontend

spec:
  type: LoadBalancer
  selecor:
    app: myapp

  ports:
  - port: 8080
    targetPort: 7575
    protocol: TCP


>When would you use this?

If you want to directly expose a service, this is the default method. 
All traffic on the port you specify will be forwarded to the service. 

>There is no filtering, no routing, etc. This means you can send almost any kind of traffic to it, 
>like HTTP, TCP, UDP, Websockets, gRPC, or whatever.

>The big downside is that each service you expose with a LoadBalancer will get its own IP address, 
>and you have to pay for a LoadBalancer per exposed service, which can get expensive.

>with cloud lb, we need to pay for each of the service that is exposed using LB as the service. as service grows
>in number, complexity to manage SSL's, scallings, Auth..etc also increases.

>Ingress controller allows us to manage all the above functionalities within the k8s cluster itself with a 
>defination file, that lives along the rest of your application deployments file.

>ingress controller can perform load balancing , Auth, SSL and (Host)URL/Path based routing configuration by being 
>inside the cluster, living as a deployment or a DAEMON SET.

>Ingress helps user access the multiple application using single externally accessible URL, 
>that you can configure to route to different services within the cluster based on url, 
>at the same time terminates the SSL/TLS.



>--------------------------------------------------------------------------------------------------------------

