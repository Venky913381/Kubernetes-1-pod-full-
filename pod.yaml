>
>-------------------------------------------POD-----------------------------------------

>pods are the most basic scheduling unit in k8s.
>pods are often Ephemeral, as on killing of one pod, controller will automatically creates a replacment for it.

>k8s doesn't run the container directaly, instead it wraps one or more containers 
>into higher leval structure called as pod.

>pods are smallest deployable unite that can be  created, scheduled and managed on k8s cluster.
>each pod will have a unique ip address within the cluster.

>pods can hold multiple containers as well, when we scale pod, the containers inside 
>the pod will get scalled together, regardless of their individual needs.

>every pod is like a seperate logical machine with its own IP, hostname, process and so on, running a single
>application. it is just a sandbox to run the containers in.

>any container in the same pod will share the same storage volume and network resource 
>and communicates using localhost.

>lifecycle of Pod_
1. pending    :- pod is accepted, but container is yet to be created.
2. running    :- pod is scheduled on node, and all containers are created and at least one is in running state.
3. succeeded  :- all container in pod existed with status 0 and will not be restarted
4. failed     :- all containers in pod have exited and at least one container have retruned the non zero status.
5. CrashLoopBackoff :-the container failed to start and tried again and again
6. unknown          :- state of pod, could not be obtained

>Restart policy in k8s
restart policy applies to all the containers in the pod.
possible values are, Always, OnFailure, and Never.

>when container in a pod exited, the kubelet restart them with an exponential back-off delay (10s, 20s, 40s...)
>that is capped at 5 minutes.
>once a container has executed for 10 minutes without any problem, the kubelet resets the restart backoff
>timer for that container.

>default restart policies for k8s objects_
1. Jobs       --> on failure or Never
2. RC         --> Always
3. DaemonSet  --> Any


>read : https://kubernetes.io/docs/concepts/workloads/pods/

>kubectl run <podname> label="key=value" --image=<image:version> -i --rm --restart=Never -- <cmd>  --->Imperative

> --image   : specifies image
> -i        : interactive mode
> -rm       : specifies, to remove pod, when stopped
> --restart : specifies restart policy for container
> --port=<> : specifies the port to be open on container
> --expose  : this will create the service for the pod
> --replicas: to create multiple pod replicas

>kubectl run pod --help
>kubectl explain pod.spec / pod.metadata

apiVersion: v1
kind: Pod

metadata: 
  name: podone
  labels: 
    owner: swapnil
    appname: app1
spec:
  containers:
  - image: nginx
    name: appContainer
    imagePullPolicy: IfNotPresent

>------------------------------------------------- 1

apiVersion: v1
kind: Pod
metadata:
  name: podtree
  labels: 
    name: pod
    appname: app2
spec:
  containers:                           
    - name: containerone
      imagePullPolicy: IfNotPresent
      image: coolgourav147/nginx-custom
      env:
        - name: name
          value: swapnil 
        - name: city
          value: pune  
      args: ["sleep", "300"]  
              
    - name: containertwo
      image: nginx
      imagePullPolicy: IfNotPresent
      env:
        - name: name
          value: nisha 
      args: ["sleep", "50"] 


 > kubectl exec podtree -c containerone -it -- bash

>-------------------------------------------------- 2

apiVersion: v1
kind: Pod
metadata:
  name: podthree
  labels: 
    name: pod
    appname: app2
spec:
  containers:
    - imagePullPolicy: IfNotPresent
      image: coolgourav147/nginx-custom
      name: containerone
      args: ["sleep", "120" ]

>-------------------------------------------------- 3

apiVersion: v1
kind: Pod

metadata: 
  name: podone
  labels: 
    owner: swapnil
    appname: app1
spec:
  containers:
  - image: nginx
    name: appContainer
    imagePullPolicy: IfNotPresent
  initContainers:
  - name: init1container
    image: nginx
    args: 
      - /bin/bash
      - -c
      - sleep 20


>while having init containers in a manifest/pod, care needed to be taken that init cotainers must exit , after
>complating their task, failing to do so, will keep the init container running , which will prevent the main 
>containers from being running.


>-------------------------------------------------- 4

>kubectl run pod --help
>kubectl explain pod.spec / pod.metadata
>kubectl explain --recursive pod | less
>kubectl apply -f <filename.yaml>  / --dry-run=client
>kubectl get pod / -o wide / --show-labels / -w (watch, to monitor in realtime)

>kubectl delete pod <pod_name> / -f <manifest>
>kubectl delete -f <pod_manifest.yml>

>kubectl exec <podname> -c <containerName> -it -- <command>
>kubectl describe pod <pod_name>
>kubectl label pod <name> label1=value1

>kubectl logs <pod_name> -c <container_name> / -f     ( for continuous logs)
>kubectl logs <container_name>
>kubectl logs -f <pod_name> --all-containers

>----------------------------------------------------5

>in multicontainer pod, if we are opening any port on perticular container, then same port will be open on 
>another container in pod. i.e. containers in a pod uses shared network and can be accessible on localhost.

we can telnet between the containers_  
>telnet localhost <port>
>netstat -nltp         : to check open ports on container
>netcat -l -p  <port>  : to open port on container

>-------------------------------------------------------6--------------------------------------------------------

> read more on_ Types of Containers in K8S_

  1. sidecar container           (log exporter)        --> send the logs created by main container to buckets
  2. ambassador/envoy container  (proxy pattern)       --> proxies-database connection
  3. adapter container           (log format changer)  --> simplifies monitoring output for service 
  4. init container              (initilazation for main container) --> Do initialization works for main container
  5. Ephemeral containers        (debugging container for main container build with distroless image)
  6. Main App Container          (container for main app or microservice)
 

>having a one container in one pod is desirable, however , there may arise a condition where we need to
>define multiple container in a single pod, either to assist/initilize/or to do extra works for the main container. 
>Or in a case, where application/microservices are tightly coupled and needed to be in vicinity of each other.

>When it comes to container security, Distroless or Minimal base images, like alpine, reduces the attack surface.
>Container images are composed of several layer of instructions. and each layer may be the source of vulnerability.
>So scanning the each layer is very crucial operation in DevSecOps.

>container scanning, is the process of identifying vulnerabilities within containers by using scanning tools
>like Synk, Anchore etc.

>it is key to container security and enables developers and cyber security teams to fix security threats in 
>containerized application before deployments.


#Smaller Docker Images

>container images should be small and lightweight.
>They should pack only the application code and its dependancies. Rest everything to be scrapped off to bring down 
>its size including the build dependancies.
>the  smaller the images the lesser is the attack on the surface to the container to the container and morever
>are easy to distribute and deploy.

>larger images can have more software vulnerabilities in the form of vulnerable dependencies 
>including potential security holes.

>better to use alpine images like, FROM golang:alpine or FROM node:alpine
>alpine images are smaller and light weighted as they are have many files and programm removed, leaving only
>the dependancies just enough to run your app.

>So, in a nutshell, Even though it is always prefferable to use latest updated images, but it is not always 
>advisable to use latest images n DevSecOps. 

>Best practices for Building docker images

 1.Do not run the container as a ROOT 
 2.Avoid copying unnecessary files, use .dockerignore to ignore the files 
 3.Merge layers
 4.Using Alpine or Distroless images as base image 
 5.Using MultiStage Builds
 6.Health Checks
 7.Avoid exposing unecessary ports
 8.Hardcoding the credentials.

>{watch euphemeral container video again......vimp}

>-------------------------------------------------------------------------------------------------------- 

>1. Init Container_

> init container will execute to perform activities that are needed in order for
> successful execution of main app container. it executes to its completion and once
> executed it will not run again. until init container executions completes, other main
> container will not start and remains in pending state.

>init containers contains Utilities or custom code for setup that are not present in an app image.
>like, sed, awk, python or dig during setup, also functions like cloning a git repo in to volume.

>if pods, init containers fails, k8s repeatedly restart the pod until the init container succeeds.
>however, if we set the restart policy for init container, then it will behave accordingly.

>init containers supports all the features of the app containers. features like, resource limit, 
>volumes, security. However, resource limits and requests are handled differently as init container
>do not exists persistanly.

>init containers do not supports probes like liveness, readiness, startup probes.
>init container executes in an order they are defined in a manifest file.
>once execution of init container is done, it will be removed from pod, with exit status as zero.

>use cases : 1. to clone the directory which is not present in image before execution of main container.

apiVersion: v1
kind: Pod
metadata:
  name: myapp
  labels:
    name: myapp
spec:
  initContainers:
  - name: clone
    image: nginx
    command:
      - git
      - clone
      - url
      - /usr/share/nginx/html
    volumeMounts:
      - name: mount
        mountpath: "/usr/share/nginx/html"

  containers:
  - name: myapp
    image: nginx
    ports: 
      - name: http 
        containerPort: 80
    volumeMounts:
      - name: mount
        mountpath: "/usr/share/nginx/html"

  volumes: 
    - name: mount
      emptyDir: {}          


>use cases : 2. to delay the application start/ or to know if application database is ready or not.
apiVersion: v1
kind: Pod
metadata:
  name: myapp
  labels:
    name: myapp
spec:
  initContainers:
  - name: clone             #db service in another pod
    image: busybox:1.28
    command: ['sh','-c','until nslookup mydb; do echo waiting for mydb service to be up, 'sleep 2; done']
  containers: 
  - name: main
    image: busybox:1.28 
    command: ['sh', '-c','echo app is running! && sleep 3600']  

>[nslookup utility will resolve the dns]
>[name_of_service.namepsace_name.svc.cluster.local]   ..fqdn i.e. internal ip/ service referenece

>--------------------------------------------------------------------------------------------------------

>2. SideCar Container_

>in realtime deployments, it is not advised to burden main application container with additional responsiblities,
>and we try to keep application image as small as possible, which reduces the surface attack on application.

>sidecar pattern , uses helper container to enhance or extend the functionality of main container.
>this way developer can work on application seperatly and other responsibilities 
>can be delegated to sidecar container

>failures in sidecar container will not impact the main application container.

>sidecar container is just like any other container, it will work in conjuction with main container, 
>so that load on main container can be reduced.

eg. A logging agent that collects logs and send them to the data aggregation system 
    and sync it to the monitoring agent.


kind: apiVersion: v1
kind: Pod
metadata:
  name: myapp
  labels:
    app: nginx 

spec:
  containers:
  - name: sidecar
    image: nginx
    command:
      - /bin/bash
    args: 
      - c
      - while true; do echo 'this is from `hostname` on `date -u` >> /var/log/index.html; sleep 1; done
    volumeMounts:
      - name: temp
        mountPath: /var/log

    - name: application
      image: nginx
      ports: 
      - containterPort: 80
      volumeMounts:
      - name: temp
        mountPath: /usr/share/nginx/html

  volumes: 
    - name: temp
      emptyDir: {}      

    
>--------------------------------------------------------------------------------------------------------

>3. Ambassador/Envoy Container_

>The Ambassador pattern employs a proxy for the main application container to talk to external word.

>they handle request/response to/from the server or external services, so it acts like a proxy or
>buffer container between external traffic and main application.

>it hides the complexity of calling external services by providing simple endpoints , like accessing 
>database servers.

>Istio uses envoy proxy containers for traffic management, TLS, dark releases, canary deployments,
>Blue-green deployements and A/B rollout.


>{watch video again......vimp}


>--------------------------------------------------------------------------------------------------------

>4. Adapter Container_

>Some application can not be integrated with standard system due to compatibility issues.
>the adapter pattern standerdizes the hetrogeneous applications by modifying the output to match the target system.

>eg, sending logs to central logging server that accepts logs in only a specific format.

>it is similar to sidecar patter, it also extends the functionality of main container, but works
>to improve compatibility issues.

>{watch video again......vimp}

>--------------------------------------------------------------------------------------------------------

>5. Ephemeral Container

>when we build multistage images using Distroless images, it does not provide us with utilities like ping,
>bash, sh , curl etc. so it is impossible to exec in to that container for the purpose of debugging it.

>so, in such case, Ephemeral containers come in to picture, Ephemeral containers are those 
>container which run in same pod as main app container and contains the Debugging utilities 
>like bash, sh, ping, curl etc. we can also  debug pod in CrashLoopBackOff state.

>Ephemeral Container share the process space with main app container. so they have a full view of the processes
>which are going on in main app container build with distroless images.

>Ephemeral container can not be restarted. 
>they do not have any port opened or any probes to perform.
>we can not specify ephemeral container in any manifest file, we have to activate it using commands, below..

> >kubectl explain pod.spec.ephemeralContainers
> >minikube start --feature-gates=EphemeralContainers=true
> >kubectl debug -it <podname> --image=busybox:1.28 --target=<podname>

>{watch euphemeral container video again......Vimp}

>--------------------------------------------------------------------------------------------------------

>6. Static Pods

>Static Pods are managed directly by the kubelet daemon on a specific node, without the API server observing them.
>Whereas most Pods are managed by the control plane (for example, a Deployment), 
>for static Pods, the kubelet directly supervises each static Pod (and restarts it if it fails).

>Static Pods are always bound to one Kubelet on a specific node. 
>The main use for static Pods is to run a self-hosted control plane: in other words, 
>using the kubelet to supervise the individual control plane components.

>The kubelet automatically tries to create a mirror Pod on the Kubernetes API server for each static Pod.
>This means that the Pods running on a node are visible on the API server, but cannot be controlled from there.

Note: The spec of a static Pod cannot refer to other API objects (e.g., ServiceAccount, ConfigMap, Secret, etc).


>--------------------------------------------------------------------------------------------------------