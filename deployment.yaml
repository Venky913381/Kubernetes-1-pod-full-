>
*Deployment_


>Deployment object is an evolution of the replica set, infact, Deployment uses RS as its backend.


apiVersion: apps/v1
kind: Deployment 

metadata:
  name: deploy1
  labels: 
    label1: dep1 
spec:
  replicas: 5
  selector: 
    matchLabels:
      appname: app
  template:   
      metadata:
        name: pod1
        labels: 
          appname: app
      spec:
        containers:
        - name: cont1
          image: coolgourav147/nginx-custom            # image: coolgourav147/nginx-custom:v2


> if we update the above deployment with modified configuration and monitor the changes
> with below command, then , it is observed that as older deployment will gradually get replaced by newer deployments.
  kubectl rollout status deployment <deploy-name> 

> the process will completed, only after all the older deployments gradually get replaced with newer deployments.
> this strategy is called as Rolling Update strategy and there is zero downtime, it is default strategy.


apiVersion: apps/v1
kind: Deployment 

metadata:
  name: deploy1
  labels: 
    label1: dep1 
  annotations:
    kubernetes.io/change-cause: "personalize change text"   


spec: 
  replicas: 10              > previous, replica is 7       
  minReadySeconds: 20     #this is the time we given for our container to be ready to accept traffic
                          #after creation in pod.

  revisionHistoryLimit: 15   # default is 10, max mumber of revisions in history k8s can store

  strategy: 
    rollingUpdate:       # here we are explictly given the RollingUpdate strategy. 
      maxSurge: 0         
      maxUnavailable: 1     > max unavailable, suggest that during replacemnt of older deployments, at a time
    type: RollingUpdate     > only 1 pod will remain unavailable. i.e. pod will get replaced one by one. 
                            # if we gave value as 3 , then at a time 3 old pods will get replaced by 3 new pod. this 
  selector:              > strategy will make sure that, 10 replicas as given (old+new),will always remain available
    matchLabels:
      appname: app
 
  template:   
      metadata:
        name: pod1
        labels: 
          appname: app
      spec:
        containers:
        - name: cont1
          image: coolgourav147/nginx-custom         

>-----------------------------------------------------------------------------------------

apiVersion: apps/v1
kind: Deployment 

metadata:
  name: deploy1
  labels: 
    label1: dep1 

spec:
  replicas: 10                    
  minReadySeconds: 20   

  strategy: 
    rollingUpdate:                > (10-1+4 = 13), so we may get 13 or 14(max)/10(min) pod active simultaneously.
      maxSurge: 4              
      maxUnavailable: 1            >max surge , are the number of pod that will get created on the top of
    type: RollingUpdate           > described replicas of pod, while replacing the older deployment.
                               > in above, as deployment ,ideally has to maintain 10 pods, but with surge , it can  
  selector:                  > create 4 pods at a time , while only 1 pod from older deployment will get unavailable.
    matchLabels:                    > this way we get continuity of services. 
      appname: app
  template:   
      metadata:
        name: pod1
        labels: 
          appname: app
      spec:
        containers:
        - name: cont1
          image: coolgourav147/nginx-custom:v2 

> if we explicity , do not gave the values of maxUnavailable or maxSurge, by default its value will
> be 25% MaxUnavailable and 25% for MaxSurge



>-----------------------------------------------------------------------------------------
> kubectl apply -f <deploy.yaml>  ;  watch "kubectl get rs -o wide"
> kubectl rollout status deployment <deploy-name>  
> kubectl rollout history deployment <deployment-name>

> kubectl delete -f <.yml>
> kubectl delete deployment <deploy-name>

#------------------------------------------------------------------------------------------

Change_Cause_ :

> kubectl rollout history deployment <deployment-name>   --> will give all revision history, however this will
                                                           > not keep any explicit details of deployment.
to keep deployment record, run a command as_
>  kubectl apply -f <deploy.yaml> --record, But this not add any custom massage.

to add custom massage for deployment, add to yml file the following in metadata of deployemnt..
>under annotation :, " kubernetes.io/change-cause: <personalize text> "
after adding annotation, there is no need to use --record flag

#-------------------------------------------------------------------------------------------

ROLLBACK_TO_SPECIFIC_REVISION_IN_HISTORY__:

> kubectl rollout undo --to-revision=<specific-rev-number>  deployment  <deploy-name> 

> if specific revision number is not specified, by default it will choose most recent last revision. 
> .i.e. -->    kubectl rollout undo  deployment  <deploy-name>

#------------------------------------------------------------------------------------------

> by default,  k8s will keep the last "10" deployment record in memory, we can change this by using
> "revisionHistoryLimit: <n>" , user spec of deployment.



*--------------------------------------RECREATE_STARTEGY--------------------------------------------

> in this startegy, all the pods from old deployemnt will simulateneously get replaced by pods from
> new deployment. this will cause the downtime, as for a brief period no pod will be available to 
> accept the traffic. but new pods will get deployed faster.
> this startegy, generally not get used in production, but for testing , this will save the time.

apiVersion: apps/v1
kind: Deployment 

metadata:
  name: deploy1
  labels: 
    label1: dep1 


spec:
  replicas: 10                    
  minReadySeconds: 20   

  strategy: 
    type: Recreate

  selector: 
    matchLabels:
      appname: app


  template:   
      metadata:
        name: pod1
        labels: 
          appname: app
      spec:
        containers:
        - name: cont1
          image: coolgourav147/nginx-custom:v2          

>--------------------------------------------------------------------------------------------------------------

RollOut Commands__:

# to get the status of the current rollout_
> kubectl rollout status deployment <deploy-name> 

# to get the history of deployments we did with deployment yml_
> kubectl rollout history deployment <deployment-name>

# to rolling back to specific deployment_ (we need to get revision number using above command)
> kubectl rollout undo --to-revision=<specific-rev-number>  deployement  <deploy-name>

# to rolling back to most recent previous deployment_
> kubectl rollout undo deployment  <deploy-name>

# to set the new image without making changes to manifest
> kubectl set image deployment/<deployment_name> <old_image_name>=<new_image_name:tag> --record=true

>---------------------------------------------------------------------------------------------------------------

*Rolling_back_a_Deployment

*ref_https://devopspro.in/blog/rollback-in-deployment/

In real life, if we make a mistake and if we want to rectify it, then we cannot go back in time 
and we cannot correct it. But in the world of Kubernetes, we can do this magicðŸª„. 
Donâ€™t you want to know how such magic can be doneðŸ¤”? Letâ€™s move closer to this magic and know it better. 
In this article, we are going to understand a very magical concept(Rolling back In Deployment) through a 
story, so stay with me till the end.

Meet harry, he is a DevOps engineer and works in an ABC private limited and his boss has given him the 
task of deploying the Nginx web server which is a basic requirement of the software on which the company 
is working. He ran the below command to deploy the Nginx server whose configuration is written in the 
nginx-deployment.yaml file.


>kubectl apply -f nginx-deployment.yaml --record=true

apiVersion: apps/v1
kind: Deployment
metadata:
  name: nginx-deployment
  labels:
    run: nginx
spec:
  replicas: 3
  selector:
    matchLabels:
      run: nginx
  template:
    metadata:
      labels:
        run: nginx
    spec:
      containers:
      - name: nginx
        image: nginx:1.14.2
        ports:
        - containerPort: 80


By running the above command, A deployment has been created with the name nginx-deployment, 
image nginx:1.14.2, and with 3 replicas. We can check the same by running â€“

kubectl get deployment

>The output will be similar to the this â€“

>NAME               READY   UP-TO-DATE   AVAILABLE   AGE
nginx-deployment   3/3     3            3           1s


>After some time, Harry was asked to upgrade the image of the same deployment from nginx:1.14.2 to nginx:1.16.1. 
>By using the below command, he updated the deploymentâ€™s image.

kubectl set image deployment/nginx-deployment nginx=nginx:1.16.1 --record=true


>The output is similar to:-

deployment.apps/nginx-deployment image updated


>To see the rollout status, run:-

kubectl rollout status deployment/nginx-deployment


>After some time again he was asked to upgrade the image from image nginx:1.16.1 to nginx:1.21.6.

kubectl set image deployment/nginx-deployment nginx=nginx:1.21.6 --record=true


As soon as the image was updated, the software stopped running due to the incompatibility of the software 
with the image nginx=nginx:1.21.6 and no one was able to access that software. Harry got a little scaredðŸ˜° 
and wondered what could happen so that he could get back the software running with the previous image.

Then after a lot of research, he came to know about the rolling back in deployment, and by using that 
approach he solved his problem. Letâ€™s see what is the rolling back in deployment and how it works.

>Whenever we make changes in the created deployment, the rollout is triggered and assigns a number to that change, 
>that number is called the revision number.


*Important_Note : 
>The rollout is triggered whenever the deployment is updated but only if the Deployment's pod 
>template (that is, .spec.template) is changed. for example, if the labels or container images of the 
>template are updated. 
>Other updates, such as scaling the Deployment, do not trigger a rollout.

So that means the rollout started when Harry updated the image, and that change got assigned a revision number.


To check the revisions of this Deployment:

kubectl rollout history deployment/nginx-deployment

>The output is similar to this:-

deployments  "nginx-deployment"
REVISION     CHANGE-CAUSE
1            kubectl apply -f nginx-deployment.yaml --record=true
2            kubectl set image deployment/nginx-deployment nginx=nginx:1.16.1 --record=true
3            kubectl set image deployment/nginx-deployment nginx=nginx:1.21.6 --record=true


>These revision numbers represent the versions of a deployment. To see the details of each revision, run,

kubectl rollout history deployment/nginx-deployment --revision=2


>Rolling Back to Previous Revision

Harry has decided to undo the current rollout and rollback to the previous stable revision

kubectl rollout undo deployment/nginx-deployment


>By running the above command,  he has reached the last deployment version running nginx:1.16.1 image. 
>But what if he wanted to rollback directly from nginx:1.21.6 to nginx:1.14.2? This is called rollback 
>to a specific revision number, this can be achieved by specifying â€“to-revision, with the below command â€“

kubectl rollout undo deployment/nginx-deployment --to-revision=1

>The output is similar to this:-

deployment.apps/nginx-deployment rolled back


>The Deployment is now rolled back to a previous stable revision. We can see this by describing the deployment â€“

kubectl describe deployment nginx-deployment


*******************************************************************************************************************