>

>Monolithic Application :-

A monolithic architecture is a traditional model of a software program, which is built as a unified unit that
is self-contained and independent from other applications. The word “monolith” is often attributed to something 
large and glacial, which isn't far from the truth of a monolith architecture for software design. 
 
A monolithic architecture is a singular, large computing network with one code base that couples all 
of the business concerns together.  To make a change to this sort of application requires updating the entire 
stack by accessing the code base and building and deploying an updated version of the service-side interface. 
This makes updates restrictive and time-consuming. 

Monoliths can be convenient early on in a project's life for ease of code management, cognitive overhead, 
and deployment. This allows everything in the monolith to be released at once.


#Advantages of a monolithic architecture

Organizations can benefit from either a monolithic or microservices architecture, depending on a 
number of different factors. 
When developing using a monolithic architecture, the primary advantage is fast development speed due to 
the simplicity of having an application based on one code base. 

The advantages of a monolithic architecture include: 

>Easy development & deployment – One executable file or directory makes deployment easier.

>Development – When an application is built with one code base, it is easier to develop.

>Performance – In a centralized code base and repository, one API can often perform the same function 
>that numerous APIs perform with microservices.

>Simplified testing – Since a monolithic application is a single, centralized unit, end-to-end testing 
>can be performed faster than with a distributed application. 

>Easy debugging – With all code located in one place, it’s easier to follow a request and find an issue.


#Disadvantages of a monolithic architecture

As with the case of Netflix, monolithic applications can be quite effective until they grow too large and 
scaling becomes a challenge. Making a small change in a single function requires compiling and testing the 
entire platform, which goes against the agile approach today's developers favor. 

The disadvantages of a monolith include: 

>Slower development speed – A large, monolithic application makes development more complex and slower.

>Scalability – You can’t scale individual components.

>Reliability – If there’s an error in any module, it could affect the entire application’s availability.

>Barrier to technology adoption – Any changes in the framework or language affects the entire application, 
>making changes often expensive and time-consuming.

>Lack of flexibility – A monolith is constrained by the technologies already used in the monolith.

>Deployment – A small change to a monolithic application requires the redeployment of the entire monolith.


*                                   ************************

>microservices Application :-

A microservices architecture, also simply known as microservices, is an architectural method that relies 
on a series of independently deployable services. These services have their own business logic and database
with a specific goal. Updating, testing, deployment, and scaling occur within each service. Microservices 
decouple major business, domain-specific concerns into separate, independent code bases. 
 
Microservices don't reduce complexity, but they make any complexity visible and more manageable by 
separating tasks into smaller processes that function independently of each other and contribute to 
the overall whole. 

Adopting microservices often goes hand in hand with DevOps, since they are the basis for 
continuous delivery practices that allow teams to adapt quickly to user requirements.


#Advantages of microservices

Microservices are by no means a silver bullet, but they solve a number of problems for growing software 
and companies. Since a microservices architecture consists of units that run independently, each 
service can be developed, updated, deployed, and scaled without affecting the other services. 

Software updates can be performed more frequently, with improved reliability, uptime, and performance. 
We went from pushing updates once a week, to two to three times a day. 

the advantages of microservices are: 

>Agility – Promote agile ways of working with small teams that deploy frequently.

>Flexible scaling – If a microservice reaches its load capacity, new instances of that service can rapidly 
>be deployed to the accompanying cluster to help relieve pressure. We are now multi-tenanant and stateless 
>with customers spread across multiple instances. Now we can support much larger instance sizes. 

>Continuous deployment – We now have frequent and faster release cycles. Before we would push out updates 
>once a week and now we can do so about two to three times a day. 

>Highly maintainable and testable – Teams can experiment with new features and roll back if something doesn’t work. 
>This makes it easier to update code and accelerates time-to-market for new features. 
>Plus, it is easy to isolate and fix faults and bugs in individual services.

>Independently deployable – Since microservices are individual units they allow for fast and easy 
>independent deployment of individual features. 

>Technology flexibility – Microservice architectures allow teams the freedom to select the tools they desire. 

>High reliability – You can deploy changes for a specific service, without the threat of bringing 
>down the entire application.

>Happier teams – The Atlassian teams who work with microservices are a lot happier, since they are 
>more autonomous and can build and deploy themselves without waiting weeks for a pull request to be approved.


#Disadvantages of microservices

When we moved from a small number of monolithic code bases to many more distributed systems and services 
powering our products, unintended complexity arose. We initially struggled to add new capabilities with 
the same velocity and confidence as we had done in the past. Microservices can add increased complexity 
that leads to development sprawl, or rapid and unmanaged growth. It can be challenging to determine 
how different components relate to each other, who owns a particular software component, or how to 
avoid interfering with dependent components. 

disadvantages of microservices can include: 

>Development sprawl – Microservices add more complexity compared to a monolith architecture, 
>since there are more services in more places created by multiple teams. If development sprawl 
>isn’t properly managed, it results in slower development speed and poor operational performance. 

>Exponential infrastructure costs – Each new microservice can have its own cost for test suite, 
>deployment playbooks, hosting infrastructure, monitoring tools, and more.

>Added organizational overhead – Teams need to add another level of communication and collaboration 
>to coordinate updates and interfaces. 

>Debugging challenges – Each microservice has its own set of logs, which makes debugging more complicated. 
>Plus, a single business process can run across multiple machines, further complicating debugging. 

>Lack of standardization – Without a common platform, there can be a proliferation of languages, 
>logging standards, and monitoring. 

>Lack of clear ownership – As more services are introduced, so are the number of teams running 
>those services. Over time it becomes difficult to know the available services a team can leverage 
>and who to contact for support.

*                                  ************************** 

Upstream and Downstream requests and responses:

------------------>upstream Service/Requests-------------------->
>Microservice A --------> Microservice B --------> Microservice C
<-----------------downstream Service/Response<-------------------

>Microservice B is upstream microservice for Microservice A, since Microservice A depends on it and 
>Microservice B is downstream microservice for Microservice C, since it adds data to the value of service C.


>Monolith or microservice application, both provides the same set of functionality, difference between them
>is the seperation of the concerns.
>it is important to understand that microserices dont live in a isolation, they enable Seperation of the concerns, 
>but they still must interact with each other.
>the issues which was inside the monolithic application are now outside in the layers between microservices 
>.i.e. the connectivity between the services.


Challenges with Microservices :

>1. security between the services : (secure certificates)
traffic between two microservice is in plain http format , which can be easily compromised, 
so security is major concern for microservices. 

>2. service discovery : Eureka
microservices needed to be aware of each other, microservices can be deployed on different hosts spread across AZ's, 
so discovery of one microservice by another microservice is concern as communication between them is 
happening over the ip, so it is important for microservices to know ip addresses of each other. 
we need to have service registry, for keeping the records of the ips of services.

>3. tracing : jaeger
as microservices are spread across the hosts, it is difficult to trace the requests and responses from them.
as request might have to propagate multiple microservices to get proper response.

>4. logging : ELK
as in microservices we have multiple services , logging becomes as issue. we need a service to keep the 
log of each microservice.

>5. testing : cucumber
testing the connectivity between microservices becomes an issue as number of services increase.

>6. fault tolerance : circuit breakers
if one microservices in loop goes down all application may stop working, as all microservices are dependent, 
so there needs a mechanism to terminate the requests if microservices becomes unreponsive.

>7. monitoring : grafana/prometheus
each application needs a monitoring to better manage the resources.




*ref_https://istio.io/latest/docs/ops/integrations/

>Zipkin , is a distributed tracing system. It gathers timing data needed to troubleshoot latency 
>problems in service architectures. Features include both the collection and lookup of this data.

>Jaeger , is an open source end to end distributed tracing system, allowing users to monitor and troubleshoot 
>transactions in complex distributed systems.

>Kiali , is an observability console for Istio, it have service mesh configuration and validation capabilities. 
>It helps you understand the structure and health of your service mesh by monitoring traffic flow to infer 
>the topology and report errors. Kiali provides detailed metrics and a basic Grafana integration, 
>which can be used for advanced queries. Distributed tracing is provided by integration with Jaeger.

>cert-manager is a tool that automates certificate management. This can be integrated with 
>Istio gateways to manage TLS certificates.

>Apache SkyWalking , is an application performance monitoring (APM) system, especially designed for microservices,
>cloud native and container-based architectures

>-------------------------------------------------------------------------------------------------------------

*ref_https://cloud.google.com/architecture/service-meshes-in-microservices-architecture 
*ref_https://medium.com/microservices-in-practice/service-mesh-for-microservices-2953109a3c9a


>Need for Service Mesh : - 

service mesh is all about service to service communication, it is capable of easily identifying the 
network issues between microservices, where these issues are occuring, at what rate these issues are occuring,
what are successful and failed requests, what are their percentage, what is their response time..etc, 
all such matrix is provided by service mesh.


with service mesh, we are removing additional logic like Ingress & Egress of Traffic from microservices, Routing of 
the traffic to microservices, Retries and Timeouts in case of failure or unresponsiveness of microservices,
Secure TLS communication between microservices, managing various certificates , Metrics of various 
microservices parameters, from application logic. 
all the above discussed responsibilities and function is carried out by service mesh.


>So moving the additional logic out from the code to seperate layer called Infrastructure layer that has
>numerous Proxies (side car containers). 
>So main application container will carry only application logic,
>while all other task discussed will be delegated to proxy container. 

>with service mesh, we are injecting secondary proxy container along with each microservice container, which 
>implements the additional logic.

>also , these proxy container can be developed using any technology, and need not to be of same
>technology as main microservices. so we can own choice of proxy container language. it also allow us to
>use polyglot code , as per need.

>these proxies are part of the DATA PLANE as these are included with main microservices containers, so
>these are components of the data plane which are intelligently routing the traffic.

>However, to configure the proxies, we need a CONTROL PLANE component, these control plane component are
>responsible for configuring the proxies for implementing various routing rules.


#Service mesh Advantages_

>1.business and communication logic is now seperated.
>2.developer needs to work only on core business logic.
>3.much cleaner and lean docker images.
>4.rich set of matrices from the application/mesh like success/failed connection, retries, timeouts,
>  thanks to the proxies intercepting the traffic.
>5.identifying the performance issues using tracing with JAEGER, zipkins.
>6.dashboard to visualize the whole mesh like KIALI/GRAFANA.
>7.chaos testing by injecting delayes and failures using tools like CHAOS-MONKEY.
>8.Weighted traffic and request based routing, canaries, A/B testing with propagating headers.
>9.additional features like mTLS between services, circuit breaking, traffic mirroring.

>     microservices--1           (data plane traffic)        microservices--2
 |CoreLogic|<-------->PROXY1  <------------------------>  PROXY2<--------->|CoreLogic|


Service Mesh :

>1.service mesh is a dedicated infrastructure layer for handling the microservice to microservice communication.
>  it is nothing but the way to inject the sideCar container along side Main application Container in to the pod
>  that mean, each and every pod will have a Proxy Side Car container along with main application container.

>2.it is responsible for the reliable delivery of requests through the complex topology of services that 
>  comprises of modern , cloud native application.

>3.implemented as a proxy in each pod, which is responsible for intercepting traffic that 
>  goes in and out of the microservices.

>4.proxies allowed to control traffic and gain insights throughout the system in the microservices architecture.

>5.it provides the observability , traffic shifting (for canary releasing), tracing, features like circuit
>  breaking and retries, timeouts and automatic mutual TLS can be configured.

>6.a service mesh does not require code changes. Instead it adds a layer of additional containers that 
>  implemets the features reliably and agnostic to technology or programming language.


*Without_Service_mesh_

>microservices A  <---------------->  microservices B


*with_Service_mesh_
>                                                                               -------|
#       microservice--1         (Data Plane _mTLS)        microservice--2              |
  |CoreLogic|<-------->PROXY1  <------------------>  PROXY2<--------->|CoreLogic|      |---> DATA PLANE
>                       ^|                            ^|                        -------|
>                configs||metrics              configs||Metrics
>                       ||                            ||
>                     ,,|v,,,,,,,,,,,,,,,,,,,,,,,,,,,,|v,,  ------|     
>                     |           CONTROL PLANE          |        |-----> Control Plane {pilot, citadel, galley}
>                     """"""""""""""""""""""""""""""""""""  ------|
                          

>Becouse of the Service mesh , many functionality listed below has been moved out of microservices logic and
>put them on the proxies.
SERVICE DISCOVERY
OBSERVABILITY (layer7 metrices, tracing , alerting)
SECURITY (end to end encryption, authorization policies, mtls)
COMMUNICATION RESILIENCY (retries, timeouts, circuit breaking, rate limiting)
ROUTING CONTROL (traffic shifting and monitoring)
LOAD BALANCING

>only business logic and bussiness matrices stays in microservices.
>incoming and outgoing requests are transparently routed through the proxies.

>In addition to the layer of proxies (DATA PLANE), a service mesh adds a so called CONTROL PLANE. it distributes
>configuration updates to all proxies and receives metrices collected by the proxies for further processing.

>Service mesh can be implemented using tools like ISTIO, LINKERD, CONSUL, TRAEFIK MESH, KUMA, 
>AWS AppMESH, OPEN SERVICE MESH(osm).

>-------------------------------------------------------------------------------------------------------------

*ISTIO_

>1.Istio is tool which provide a service mesh for microservices. It addresses the challanges developers
>  and operators face with a distributed or microservices architecture.

>2.Istio is the most popular service mesh , it was developed by google and IBM.
>3.Istio implements all the service mesh features such as matrics, logging, tracing, traffic management,
>  traffic routing, circuit breaking, mTLS and authorization.

>4.Istion integrates with prometheous, grafana, and Jaeger and the service mesh dashboard kiali

>5.Istio uses ENVOY pattern by default as service proxy, a popular open source proxy.

>6.In istio version 1.5, the whole control plane was unified into a single process (ISTIOD ,it consist of
>  control plane components such as pilot, citadel, galley.)

>7.ISTIOD communicates with the proxies to distribute configuration, receive recorded network traffic in the
>  form of metrics and telemetry data and manage certificates for mutual TLS (mTLS) communication.

>8.Ingress service for istio is exposed as a load balancer service type. that is why we need a load balancer 
>  service enables in a cluster.

HOW DOES ISTIO WORKS IN K8S :

At high leval, istio works by deploying a proxy container alongside the main application container
in the pod for each microservices in our application.

This envoy proxy , which is often reffered to as a SideCar, intercpts all the traffic of the main
application container, providing telemetry data, mTLS, traffic routing feature for the application.

this way it reduces the burden on main application container. it reduces the image size and reduces
attack surfce area of the microservices.


why SideCar pattern:

>in realtime deployments, it is not advised to burden main application container with additional responsiblities,
>and we try to keep application image as small as possible, which reduces the surface attack on application.

>sidecar pattern , uses helper container to enhance or extend the functionality of main container.
>this way developer can work on application seperatly and other responsibilities 
>can be delegated to sidecar container

>failures in sidecar container will not impact the main application container.

>sidecar container is just like any other container, it will work in conjuction with main container, 
>so that load on main container can be reduced.

eg. A logging agent that collects logs and send them to the data aggregation system 
    and sync it to the monitoring agent.


ENVOY PROXY :

>Istio uses EnvoyProxy as sidecar for all microservices injected as a side car container.
>Envoy is a high performance proxy developed in c++ and it itercepts all inbound and outbound traffic for
>all microservices in service mesh.

>Proxies Implements features like_
DYNAMIC SERVICE DISCOVERY
LOAD BALANCING
TLS Communication
TLS TERMINATION
CIRCUIT BREAKING
HEALTH CHECKS
CANARY ROLLOUTS
Staged rollouts with %-based traffic split
A/B ROLLOUTS/DARK DEPLOYMENTS
FAULT INJECTION
RICH METRICS
HTTP/2 and gRPC proxies


>Secure service-to-service communication in a cluster with mTLS encryption, and
>strong identity-based authentication and authorization

>Automatic certificates rotation at proxy level for secure mTLS communication ,without any change to microservice.

>Traffic routing using weighted and request based rules.

>Tracing , Monitoring and logging for detecting and fixing the issues.

>Automatic load balancing for HTTP, gRPC, WebSocket, and TCP traffic.

>identifying the performance /relibility issues through metrics.

>debug services and tracing using tools like zipkins and jaeger resp.

>Fine-grained control of traffic behavior with rich routing rules, retries, failovers, 
>and fault injection for chaos testing.

>A pluggable policy layer and configuration API supporting access controls, rate limits and quotas.

>Automatic metrics, logs, and traces for all traffic within a cluster, including cluster ingress and egress

>metrics visualization using tools like prometheus, grafana.


*                                    *******************************


ISTIO ARCHITECTURE AND CORE FUNCTIONS :

>with version 1.5, control plane components like Pilot, Citadel, Galley, Mixer were combined into single 
>component called istiod. (istio daemon , is a pod)

>Istiod replaces the control plane components and handle configuration and certificate distribution 
>sidecar injection and more. (istioD unified the control plane components in to single process)


DATA PLANE vs CONTROL PLANE :

#DATA_PLANE_ 

>the data plane is only composed of Main application containers and the Envoy Proxies, which is deployed 
>as sidecar container in each pod.
*note_ Istio will not inject the sidecar container in a pod which was exiting before labelling 
       the namespace with Istio-enabl=true label. only pods which was created after labelling the
       namespace will have sidecar injected in to them.

>any incoming or outgoing requests/responses from pod will pass through these proxy sidecars.

>these proxies control all the network communications between microservices.

b
#CONTROL_PLANE_

>control plane is the brain of the service mesh.
>it provides service discovery, configuration and certificates management to envoy proxies by issuing
>mTLS certificates at the runtime.

>it collects telemetry data and other matrices from proxies.

>PILOT, CITADEL, GALLEY, MIXER, SIDECAR INJECTOR, GATEWAY are the part of the control plane.

>istio 1.5 itroduced ISTIOD, a control plane that combines all above components in to single istiod daemon.
>while, mixer components is removed all together.

*ref_https://istio.io/v1.4/docs/ops/deployment/architecture/
*ref_https://istio.io/latest/docs/ops/deployment/architecture/


>1.PILOT :- (Service Discovery and All Configurations)
pilot is not a container running in a istiod pod, it is one of the component of istio application.
pilot provides a service discovery i.e whenever a new pod gets created within the mesh, the pod will send its 
own information to the pilot and this information is send by the envoy proxy container.
Now the pilot , sends the information about this new pod in mesh to the all the other envoy proxy's (pods)
in mesh. so that other pods will discover it. its all done automatically by pilot.

it uses envoys api to communicates and configure them. it parses the high level rules defined in the istio
manifest and converts that to envoy configuration.
Configuratios for service discovery, traffic managements, A/B testing, Blue-Green deployments, Canry rollouts,
retries, timeouts and circuit breaking etc, can be injected in to envoy proxies.

(before version v1.5, it runs as a seperate pod)

>2.CITADEL :- (Certifications, mTls , Authentication and Authorizations)
it acts as local Certification Authorization authority, it provides secure communication among service by 
managing user authentication, issuing and rotating certificates to envoy and credentials managements.

it enables mTLS, we can implemets mTLS by configuring every pod with a certificates. but we end up managing 
hundreds of certificates ourself like rotation and issuing. Citadel componet manages this task automatically.

(before version v1.5, it runs as a seperate pod)

>3.GALLEY :-  (Config Validations, Format Coversion)
Galley is Istio's configuration validation, ingestion, processing and distribution component. 
It is responsible for insulating the rest of the Istio components from the details of obtaining user 
configuration from the underlying platform (e.g. Kubernetes).

Galley reads the yaml configuration files and convert it in to istio format. so all the manifest
we executes using kubectl, it first goes to the galley , where it gets converted in to istio format
and after that it gets implemented.

(before version v1.5, it runs as a seperate pod)

>4.Mixer :- (for < v1.5 , removed)
Mixer is a platform-independent component. Mixer enforces access control and usage policies across the service mesh, 
and collects telemetry data from the Envoy proxy and other services. The proxy extracts request level attributes,
and sends them to Mixer for evaluation.

>5.SideCar Injectors :-
it injects envoy sidecar container in to pods for istio enabled namepsaces.
we have to enable Istio injection for namespaces in order to inject sidecar container proxies.
this is done by labeling the namespace for Sidecar proxy injection as below

>kubectl label namepsace <ns_name> istio-injection=enabled



Istio Features :

>1. Traffic Control
The main feature of Istio is its role in traffic management. It controls the flow of traffic between services
by implementing routing rules through its Envoy proxies. By deploying proxies, Istio directs traffic 
and API calls without making any changes to the service itself. This allows users to perform canary rollouts, 
staged rollouts, and A/B testing.

>2. Observability
The platform controls and observes all incoming and outgoing traffic within the network layer. 
Therefore, it collects large amounts of data that provide useful insight for future development.

>3. Security
While developers secure the application from potential threats and hacks, Istio authorizes, authenticates, 
and encrypts all internal communication. Pods and services talk to each other and transfer data under 
Istio's policies.

>4. Monitoring
the proxies in the data plane can measure basic information about the network traffic such as latency
or throughput, and other matrices that can be used for implementing alarms and further anakysis.

>5. Tracing
a request to a microservice might result in other request, Tracing helps to understand these dependancies, thus 
facilitating root cause analysis. this is done using "unique_id" in headers of HTTP requests. as a part of 
HTTP headers and that information is then transffered to each outgoing request.
the code of the microservices has to capture these headers and transfer them in their outgoing request. The tracing
data can also be used to create dependancy graphs.

>6. Communication Resilience
resilience ensures that each individual microservice still works even if other microservice fails.
if microservice calls another microservice , and if that microservice fails/ not reachable , this will
impact the upstream microservice.
due to cascading error, the whole system will become quite unstable, To avoid cascading errors or to have 
proper resilience , Istio provides features such as _ TIMEOUTS, RETRIES, AND CIRCUIT BREAKERS.

>7. Routing
istio offers advance routing capabilities ( like routing certain percentage of traffic to v1 of service A
and rest of traffic to v2 of service A ) in the form of object like VirtualService, DestinationRules, 
IngressGateways for canaries, A/B, Dark releases etc.

>8. mTLS
istion uses mutual TLS authentication to encrypt microservice to microservice traffic .
istio provides developers with certificates Authority (citadel) to generate , distributes and revoke 
certificates for proxy.

*                                    *******************************


ISTIO INSTALLATION :

*ref_https://istio.io/latest/docs/setup/getting-started/

WE can install istio in three different ways_

>1. using, istioctl install/ Istio Operator
>2. using, istioctl manifest generator (recommended)
>3. install using helms chart

>first we need download the istio binary and add it to the system path(windows). 
>so that the istio command will works_

>On minikube
1.start minikube cluster
2.get minikube ip                   :- minikube ip 
3.get minikube metallb addon enable :- minikube addon enable metallb
4.configure metallb                 :- minikube addon configure metallb , (enter lb's startip and endip)


>Istio Profiles 
istio comes with build in configuration profiles, that can be used when installing istio for customization
of istio control plane and of the sidecars for the istio data plane.

>istioctl profile list   _ will give list of profiles.
DEFAULT
DEMO
EMPTY
EXTERNAL
MINIMAL
OPENSHIFT
PREVIEW
REMOTE

default: enables components according to the default settings of the IstioOperator API. 
This profile is recommended for production deployments and for primary clusters in a multicluster mesh. 
You can display the default settings by running the istioctl profile dump command.

demo: configuration designed to showcase Istio functionality with modest resource requirements. 
It is suitable to run the Bookinfo application and associated tasks. This is the configuration that 
is installed with the quick start instructions.

minimal: same as the default profile, but only the control plane components are installed. 
This allows you to configure the control plane and data plane components (e.g., gateways) using separate profiles.

external: used for configuring a remote cluster that is managed by an external control plane or by a 
control plane in a primary cluster of a multicluster mesh.

empty: deploys nothing. This can be useful as a base profile for custom configuration.

preview: the preview profile contains features that are experimental. This is intended to explore new 
features coming to Istio. Stability, security, and performance are not guaranteed - use at your own risk.


>  Core components           default	  demo   	minimal	   external	   empty   	preview
>---------------------------------------------------------------------------------------			
  istio-egressgateway		                 ✔				
*---------------------------------------------------------------------------------------  
  istio-ingressgateway	       ✔	      ✔				                                  ✔
*---------------------------------------------------------------------------------------  
  istiod	                     ✔	      ✔	       ✔			                         ✔
>---------------------------------------------------------------------------------------

****************************************************************************************

>  Addons                    default	  demo   	minimal	   external	   empty   	preview
>---------------------------------------------------------------------------------------			
  Grafana   	                  			  ✔
*---------------------------------------------------------------------------------------  
  Prometheus          	       ✔	     ✔				                                  ✔
*---------------------------------------------------------------------------------------  
  Kiali 	                      	      ✔	        			                         
*---------------------------------------------------------------------------------------  
  Istio-Tracing         	      	      ✔				                                  
>--------------------------------------------------------------------------------------- 


installation :
first download the istio binary and add it to the system path.

>install with istioctl_   
istioctl install                          _ this will install default profile (not recommanded/need CR & CRD)
istioctl install --set profile=demo -y    _ this will install demo profile    (not recommanded/need CR & CRD)

>customize the installation by generating manifests_
istioctl manifest generate --set profile=demo > istio-installation.yaml (usig demo profile , any name for yaml)
kubectl apply -f istio-installation.yaml
istioctl verify-install -f istio-installation.yaml      _verify installation
kubectl get all -n istio-system                         _check deployed objects in istio ns
istioctl version
   
>uninstallation
istioctl experimental/x/exp          _ show beta & experimental commands
istioctl x uninstall --purge


*                                    *******************************

using istio : 

>install kiali, jaeger, prometheus
in downloaded istio folder, we will get yaml for all the tool
change/add the service type for kiali, jaeger, grafana, prometheus  to node port and hard code the ports.

istio provides the ingressGateway to expose the service/application ouside of thecluster.

kubectl apply -f grafana.yaml -f jaeger.yaml -f kiali.yaml -f prometheus.yaml 
kubectl get all -n istio-system

>Enable SideCar injection on a Namaspace

to automatically inject proxy containers into pods, the namespace to be used by an application must be 
labled with  "istio-injection=enabled"
>kubectl label namepsace <ns_name> istio-injection=enabled

>check if sidecar injection is enabled 
kubectl get ns
istioctl analyze
kubectl label namespace <ns name> istio-injection=enabled (if not) 
kubectl apply -f istio-injection.yaml (look above)



*note : istio do not inject the sidecar/proxy to the pods, which are already running/existing in the namespace,
        before labeling/enabling the istio pod injection. only pods created after enabling the injection
        on Namespace will get the proxy containers.

>-------------------------------------------------------------------------------------------------------------
>to be continue............platinum members...

>read_
istio traffic management
virtual service
destination rules
ingress/egress gateway
istion service Entry
istio deployments startegies
canary deployments

*--------------------------------------------------------------------------------------------------------(Deep_Tech)

Istio Traffic Management :

The pod needs to meet some pre-requisites to be the part of istios service mesh, these are _

>1.the namespace , where pods are created need to be labeled with istio enabled label

>2.all the pods needs to be always run behind one or more service

>3.pod should not run with security context with user id 1337.
   i.e. if we are running the pod with user other than root user , then user id of that user must not be 1337.

>4.pod should run with NET_ADMIN and NET_RAW capabilities
   
>5.pods/deployments should have labels "app" and "version" (it is best practice rather than requirement)


Istio's Traffic managements have following componets :
virtual service
destination rules
ingress gateways
egress gateways
service entries
sidecars

*ref_https://istio.io/latest/docs/concepts/traffic-management/        --->(v1.14)
*ref_https://istio.io/v1.5/pt-br/docs/reference/config/networking/    --->(v1.5 )

>                                                                               ------------|
>                                 app.prod.sv.cluster.local  (dns)                          |
>                                            |                                              |
>                       ---------------------------------------------                       |--->Virtual Service yml
>                       |                                           |                       |
>      app.prod.sv.cluster.local(old)                app2.prod.sv.cluster.local(new)        |
>                    |                                                 |        ------------|
>       --------------------------                       --------------------------     -------|
>       |           |            |                       |            |           |            | --->Destination
>     [pod1]     [pod2]       [pod3]                  [pod1]        [pod2]      [pod3]         |       rules
>                                                                                       -------|        yml
>                {80%}                                              {20%}



#VirtualService : (analogous to k8s Ingress object/resource+ more)

>A virtual service lets you configure how requests will be routed to the service within an Istio service mesh.

Each virtual service consists of a set of routing rules that are evaluated in order, letting Istio match 
each given request to  the virtual service to a specific real destination within the mesh. 

building on the basic connectivity and discovery is provided by Istio and your platform. 

Your mesh can require multiple virtual services or none depending on your use case.

>A virtualService defines the 'set of traffic routing rules' to apply when a (HOST) is addressed.
(host : the address used by a client when attempting to connect to k8s service)
(address can be a k8s service itself or it can be DNS name also)


*                                  *********************************

#DestinationRules :

>destination rule defines the set of service/pods where traffic should go.

DestinationRule defines policies that apply to traffic intended for a service after routing has occurred.

These rules specify configuration for load balancing, connection pool size from the sidecar, and outlier 
detection settings to detect and evict unhealthy hosts from the load balancing pool.


>-------------------------------------------------------------------------------------------------------------

#Demo_1 (above diagram  )

here we are having two version of same application, one is old one and other is new one. 
Both microservices are backed by their own set of services_


>Deployment_1 _

apiVersion: apps/v1
kind: Deployment 
metadata:
  name: app-deployment
 
spec:
  replicas: 1
  selector: 
    matchLabels:
      chapter: istio
      topic: traffic-management
      app: app
      version: v2
      
  template:   
      metadata:
        name: app-pod
        labels: 
          chapter: istio
          topic: traffic-management
          app: app
          version: v2

      spec:
        containers:
        - name: istio
          image: deepcloud2208/app:v2
          ports:
          - containerPort: 80


>service_1 _ [app-svc.prod.svc.cluster.local]

apiVersion: v1
kind: Service
metadata:
  name: app-svc
  labels: 
    chapter: istio
    topic: traffic-management
    app: app
    version: v2
spec:
    type: ClusterIP
    ports:
    - port:  8080
      targetPort:  80
    selectors: 
      chapter: istio
      topic: traffic-management
      app: app
      version: v2  



>Deployment_2 _

apiVersion: apps/v1
kind: Deployment 
metadata:
  name: app2-deployment
 
spec:
  replicas: 1
  selector: 
    matchLabels:
      chapter: istio
      topic: traffic-management
      app: app2
      version: v2
      
  template:   
      metadata:
        name: app2-pod
        labels: 
          chapter: istio
          topic: traffic-management
          app: app2
          version: v2

      spec:
        containers:
        - name: istio
          image: deepcloud2208/app2:v2
          ports:
          - containerPort: 80


>service_2 _ [app2-svc.prod.svc.cluster.local]

apiVersion: v1
kind: Service
metadata:
  name: app2-svc
  labels: 
    chapter: istio
    topic: traffic-management
    app: app2
    version: v2
spec:
    type: ClusterIP
    ports:
      port:  8080
      targetPort:  80
    selectors: 
      chapter: istio
      topic: traffic-management
      app: app2
      version: v2  



>virtual Service _      

apiVersion: networking.istio.io/v1alpha3
kind: VirtualService
metadata:
  name: istio-virtual-svc

spec:
  hosts:
  - app-svc.prod.svc.cluster.local               #top leval @ above diagram , FULL FQDN, prod is ns

  http:
  - name: virtual-service-routes
    route:
    - destination:
        host: app-svc.prod.svc.cluster.local
        subset: app-service-subset           # look at destination rules
      weight: 80                             #80% traffic will goes to this service

    - destination:
        host: app2-svc.prod.svc.cluster.local
        subset: app2-service-subset          # look at destination rules
      weight: 20                             #20% traffic will goes to this service



(note:-as we have two different routes/services in Virtual Service,we need to create two diffeent destination rules.)
(care must be taken that "host" part needed to be same in both VS and their DR resp.)
>destination_rule_1 _

apiVersion: networking.istio.io/v1alpha3
kind: DestinationRule
metadata:
  name: istio-destination-rule1

spec:
  host: app-svc.prod.svc.cluster.local
  subsets:
  - name: app-service-subset           # name will relate it to the Virtual service subset
    labels:                            # it not labeling the subject, rather it is selectors to select 
      app: app
      version: v2
      chapter: istio
      topic: traffic-management
    trafficPolicy:
      loadBalancer:
        simple: ROUND_ROBIN


>destination_rule_2 _

apiVersion: networking.istio.io/v1alpha3
kind: DestinationRule
metadata:
  name: istio-destination-rule2

spec:
  host: app2-svc.prod.svc.cluster.local
  subsets:
  - name: app2-service-subset
    labels:                            # it not labeling the subject, rather it is selectors to select 
      app: app2
      version: v2
      chapter: istio
      topic: traffic-management
    trafficPolicy:
      loadBalancer:
        simple: ROUND_ROBIN      


>kubectl get vs -n <ns>
>kuebctl get dr -n <ns>
>kubectl describe vs -n <ns>
>kuebctl describe dr -n <ns>


>if we access the application, out of service mesh, then traffic will be load balance by k8s service , resolved by
>kube-dns. to route the traffic as per rules defined in Virtual service , we need to configure ingress gateway.

>-------------------------------------------------------------------------------------------------------------
**************************************************************************************************************
>-------------------------------------------------------------------------------------------------------------


>                                                                               
>                        retail-svc.prod.svc.cluster.local (retail)                         
>                                            |                                              
>         (/electronics)--------------------------------------------(/books)                
>                       |                                          |                       
>   electronics-svc.prod.svc.cluster.local                books-svc.prod.svc.cluster.local        
>                    |                                                 |        
>       --------------------------                       --------------------------     
>       |           |            |                       |            |           |            
>     [pod1]     [pod2]       [pod3]                   [pod1]       [pod2]      [pod3]        
>                                                                                       


>in above schematic, there are three different services, electronics-svc, books-svc, retail-svc.
>also electronics-svc, books-svc are not used directaly.

>i.e. only , if we append /electronics to retail-svc.prod.svc.cluster.local , it takes us to electronics and 
>if we append /books to retail-svc.prod.svc.cluster.local , it takes us to books.




#demo_2

>Deployment_1 _ books

apiVersion: apps/v1
kind: Deployment 
metadata:
  name: books-depl
 
spec:
  replicas: 1
  selector: 
    matchLabels:
      chapter: istio
      topic: traffic-management
      app: books
      version: v1
      
  template:   
      metadata:
        name: books-pod
        labels: 
          chapter: istio
          topic: traffic-management
          app: books
          version: v1

      spec:
        containers:
        - name: books-cont
          image: deepcloud2208/books:v1
          ports:
          - containerPort: 80

>service_1 _ books

apiVersion: v1
kind: Service
metadata:
  name: books-svc
  labels: 
    chapter: istio
    topic: traffic-management
    app: books
    version: v1
spec:
    type: ClusterIP
    ports:
    - port:  8080
      targetPort:  80
    selectors: 
      chapter: istio
      topic: traffic-management
      app: books
      version: v1

> **************************

>Deployment_1 _ electronics

apiVersion: apps/v1
kind: Deployment 
metadata:
  name: electronics-depl
 
spec:
  replicas: 1
  selector: 
    matchLabels:
      chapter: istio
      topic: traffic-management
      app: electronics
      version: v1
      
  template:   
      metadata:
        name: electronics-pod
        labels: 
          chapter: istio
          topic: traffic-management
          app: electronics
          version: v1

      spec:
        containers:
        - name: electronics-cont
          image: deepcloud2208/electronics:v1
          ports:
          - containerPort: 80

>service_1 _ electronics

apiVersion: v1
kind: Service
metadata:
  name: electronics-svc
  labels: 
    chapter: istio
    topic: traffic-management
    app: electronics
    version: v1
spec:
    type: ClusterIP
    ports:
    - port:  8080
      targetPort:  80
    selectors: 
      chapter: istio
      topic: traffic-management
      app: electronics
      version: v1

> **************************

>Deployment_1 _ retail

apiVersion: apps/v1
kind: Deployment 
metadata:
  name: retail-depl
 
spec:
  replicas: 1
  selector: 
    matchLabels:
      chapter: istio
      topic: traffic-management
      app: retail
      version: v1
      
  template:   
      metadata:
        name: retail-pod
        labels: 
          chapter: istio
          topic: traffic-management
          app: retail
          version: v1

      spec:
        containers:
        - name: retail-cont
          image: deepcloud2208/retail:v1
          ports:
          - containerPort: 80

>service_1 _ retail

apiVersion: v1
kind: Service
metadata:
  name: retail-svc
  labels: 
    chapter: istio
    topic: traffic-management
    app: retail
    version: v1
spec:
    type: ClusterIP
    ports:
    - port:  8080
      targetPort:  80
    selectors: 
      chapter: istio
      topic: traffic-management
      app: retail
      version: v1

> **************************

>virtual Service _      

apiVersion: networking.istio.io/v1alpha3
kind: VirtualService
metadata:
  name: retail-portal-svc

spec:
  hosts:
  - retail-svc.prod.svc.cluster.local              

  http:

  - name: books-routes
    match:                       # i.e. when retail-svc.prod.svc.cluster.local/books , below routing will
    - uri:                       # get applied
        prefix: "/books"  
    rewrites: 
      uri: "/"                   # as there is no service declaired by "/books", it is needed to rewrites the 
    route:                       # service as  retail-svc.prod.svc.cluster.local/books, REWRITE BLOCK DO THAT.       
    - destination:
        host: books-svc.prod.svc.cluster.local
        subset: books-service-subset                                


  - name: electronics-routes
    match: 
    - uri:
        prefix: "/electronics"  
    rewrites: 
      uri: "/"    
  - route:
    - destination:
        host: electronics-svc.prod.svc.cluster.local
        subset: electronics-service-subset          


  - name: retail-routes  
  - route:
    - destination:
        host: electronics-svc.prod.svc.cluster.local
        subset: electronics-service-subset


>destination_rule_1 _ books

apiVersion: networking.istio.io/v1alpha3
kind: DestinationRule
metadata:
  name: books-destination-rule

spec:
  host: books-svc.prod.svc.cluster.local
  subsets:
  - name: books-service-subset         
    labels:                           
      app: books
      version: v1
      chapter: istio
      topic: traffic-management
    trafficPolicy:
      loadBalancer:
        simple: ROUND_ROBIN


>destination_rule_2 _ electronics

apiVersion: networking.istio.io/v1alpha3
kind: DestinationRule
metadata:
  name: electronics-destination-rule

spec:
  host: electronics-svc.prod.svc.cluster.local
  subsets:
  - name: electronics-service-subset         
    labels:                           
      app: electronics
      version: v1
      chapter: istio
      topic: traffic-management
    trafficPolicy:
      loadBalancer:
        simple: ROUND_ROBIN

>destination_rule_3 _ retail

apiVersion: networking.istio.io/v1alpha3
kind: DestinationRule
metadata:
  name: retail-destination-rule

spec:
  host: retail-svc.prod.svc.cluster.local
  subsets:
  - name: retail-service-subset         
    labels:                           
      app: retail
      version: v1
      chapter: istio
      topic: traffic-management
    trafficPolicy:
      loadBalancer:
        simple: ROUND_ROBIN        



>-------------------------------------------------------------------------------------------------------------
**************************************************************************************************************
>-------------------------------------------------------------------------------------------------------------

>                                                                               
>                              retail-svc.prod.svc.cluster.local                            
>                           50%             |          50%                                      
>         (version_1)---------------------------------------------------(version_2)                
>                    |                                                 |                             
>                    |                                                 |        
>       --------------------------                       -------------------------     
>       |           |            |                       |            |           |            
>     [pod1]     [pod2]       [pod3]                  [pod1]        [pod2]      [pod3] 

>       chapter: istio                                       chapter: istio
>       topic: traffic-management                            topic: traffic-management
>       app: ab                                              app: ab
:       version: v1                                          version: v2


above, we are deploying two version of the same app version v1 and v2. so there will only be one service.


#Demo_3

>Deployment_1 _ 

apiVersion: apps/v1
kind: Deployment 
metadata:
  name: ab-depl1
 
spec:
  replicas: 1
  selector: 
    matchLabels:
      chapter: istio
      topic: traffic-management
      app: ab
      version: v1
      
  template:   
      metadata:
        name: ab-pod
        labels: 
          chapter: istio
          topic: traffic-management
          app: ab
          version: v1

      spec:
        containers:
        - name: ab-cont
          image: deepcloud2208/ab:v1
          ports:
          - containerPort: 80


>Deployment_2 _ 

apiVersion: apps/v1
kind: Deployment 
metadata:
  name: ab-depl2
 
spec:
  replicas: 1
  selector: 
    matchLabels:
      chapter: istio
      topic: traffic-management
      app: ab
      version: v2
      
  template:   
      metadata:
        name: ab-pod
        labels: 
          chapter: istio
          topic: traffic-management
          app: ab
          version: v2

      spec:
        containers:
        - name: ab-cont
          image: deepcloud2208/ab:v2
          ports:
          - containerPort: 80



>service_

apiVersion: v1
kind: Service
metadata:
  name: ab-svc
  labels: 
    chapter: istio
    topic: traffic-management
    app: ab
                                 # no, version: v?
spec:
    type: ClusterIP
    ports:
    - port:  8080
      targetPort:  80
    selectors: 
      chapter: istio
      topic: traffic-management
      app: app


>virtual Service _      

apiVersion: networking.istio.io/v1alpha3
kind: VirtualService
metadata:
  name: ab-vs

spec:
  hosts:
  - ab-svc.prod.svc.cluster.local              

  http:
  - name: ab-routes 

    route:                            
    - destination:
        host: ab-svc.prod.svc.cluster.local
        subset: v1
      weight: 50                                  
                                            #both have same destination service, only subset is different
  - route:
    - destination:
        host: ab-svc.prod.svc.cluster.local
        subset: v2         
      weight: 50


>destination_rule_   (as we have only one service , only one dr needed, with two subsets)

apiVersion: networking.istio.io/v1alpha3
kind: DestinationRule
metadata:
  name: ab-destination-rule

spec:
  host: ab-svc.prod.svc.cluster.local
  subsets:

  - name: v1   
    labels:                           
      app: ab
      version: v1
      chapter: istio
      topic: traffic-management
    trafficPolicy:
      loadBalancer:
        simple: ROUND_ROBIN
  
  - name: v2 
    labels:                           
      app: ab
      version: v2
      chapter: istio
      topic: traffic-management
    trafficPolicy:
      loadBalancer:
        simple: ROUND_ROBIN



>-------------------------------------------------------------------------------------------------------------
**************************************************************************************************************
>-------------------------------------------------------------------------------------------------------------

>till now, it is only possible to access the pods from within the cluster from one pod to another , 
>to access the pods in mesh from outside of cluster, we need to defines the gateways.

>gateway act as a entrypoint to the cluster.

# Gateway 

when we try to access/curl the service from outside of mesh or from node itself (from node, not pod) , 
using full fqdn of service, request first goes to /etc/resolve.conf, from where it gets resolved to 
CORE-DNS (kube dns) and then to the service, which do the load bancing , without keeping proxy container in loop. 
it bypasses the proxy all together.

>(out_of_mesh)curl fqdn_service1 ---> /etc/resove.conf ---> CoreDNS(kube-dns) ---> k8s service ----> POD 

when we try to access/curl the same from within the pod within mesh, service get routed via Proxy , and 
based on routing rule it routes the traffic to itself or to other pods.

>gateways are standalone envoy proxies i.e they runs as a pod. and only one container is
>running, which is envoy proxy.

>these gateways facilates the traffic from outside to in into the cluster and traffic from clutser 
>to access the database or other application, which may reside outside of the cluster.

there are two types of gateways, Ingress gateway and egress gateway.
>ingress gateway allow traffic from outside of the cluster in to the cluster, similarly,
>egress gateway allow traffic from the cluster to exit the cluster, such as to Datbases , which may
>reside outside of the cluster/mesh. 

>as gateways are standalone proxy's , we can attach virtual service and destination rule to these proxies.
>so it not just provide the Entry and Exit to the container but also provides the intelligent routing using VS&DR.

>service browser--->[proxy]--Ingress g/w ---->[frontend pod <---> Backend Pod]--->[proxy]--egress g/w ---> database


Istio Installation itself provides a both Ingress and Egress gateways , which are deployed using deployments
and resides at istio-system namespace.
However, we can provide our own custom ingress and egress gateways.
Istio installation also provides a Ingress gateway service.

Gateway object enables the ingress gateway proxy to accept the traffic from outside and Virtual service
with "gateways:" keyword, will provies a routing rules needed to for this envoy proxy.

we need to create a seperate routing rules i.e. seperate Vitual service for within cluster communication.

in Istio provided ingress gateway , we automatically have a node port mappings to predefine  ports like
port 80:31797, 443:30583, 15029:30923.. etc, we can only expose those port with istio provided gateway.

>for ingress gateway, by default everything is allowed. i.e. all traffic is allowed inside the pod via proxy.


*demo :-

>Deployment_1 _

apiVersion: apps/v1
kind: Deployment 
metadata:
  name: app-deployment
 
spec:
  replicas: 1
  selector: 
    matchLabels:
      chapter: istio
      topic: traffic-management
      app: app
      version: v2
      
  template:   
      metadata:
        name: app-pod
        labels: 
          chapter: istio
          topic: traffic-management
          app: app
          version: v2

      spec:
        containers:
        - name: istio
          image: deepcloud2208/app:v2
          ports:
          - containerPort: 80

>service_1 _

apiVersion: v1
kind: Service
metadata:
  name: app-svc
  labels: 
    chapter: istio
    topic: traffic-management
    app: app
    version: v2
spec:
    type: ClusterIP
    ports:
    - port:  8080
      targetPort:  80
    selectors: 
      chapter: istio
      topic: traffic-management
      app: app
      version: v2  


>Deployment_2 _

apiVersion: apps/v1
kind: Deployment 
metadata:
  name: app2-deployment
 
spec:
  replicas: 1
  selector: 
    matchLabels:
      chapter: istio
      topic: traffic-management
      app: app2
      version: v2
      
  template:   
      metadata:
        name: app2-pod
        labels: 
          chapter: istio
          topic: traffic-management
          app: app2
          version: v2

      spec:
        containers:
        - name: istio
          image: deepcloud2208/app2:v2
          ports:
          - containerPort: 80

>service_2 _

apiVersion: v1
kind: Service
metadata:
  name: app2-svc
  labels: 
    chapter: istio
    topic: traffic-management
    app: app2
    version: v2
spec:
    type: ClusterIP
    ports:
      port:  8080
      targetPort:  80
    selectors: 
      chapter: istio
      topic: traffic-management
      app: app2
      version: v2  


>Gateway Object_

apiVersion: networking.istio.io/v1alpha3
kind: Gateway
metadata:
  name: istio-ingress-gateway

spec:

  selector:
    app: istio-ingressgateway        # to select Gateway Pod, provided by istio installation.
    istio: ingressgateway            # selector by label provided to istio ingress pod

  servers:
  - port:
      number: 80
      name: app
      protocol: HTTP
    hosts:
    - uk.bookinfo.com
    - "app-svc.prod.svc.cluster.local"  #only allow ingress traffic from this fqdn/dns
    

>Gateway Virtual Service / Virtual Service

apiVersion: networking.istio.io/v1alpha3
kind: VirtualService
metadata:
  name: istio-virtual-svc

spec:
  hosts:                                #hosts has to be same as hosts in gateway file
  - uk.bookinfo.com
  - app-svc.prod.svc.cluster.local     

  gateways:                              # wiring the gateway with virtual service 
  - virtual-service-routes        

  http:
  - name: virtual-service-routes
    route:
    - destination:
        host: app-svc.prod.svc.cluster.local
        subset: app-service-subset         
      weight: 80                            

  - route:
    - destination:
        host: app2-svc.prod.svc.cluster.local
        subset: app2-service-subset         
      weight: 20 


>destination_rule_1 _

apiVersion: networking.istio.io/v1alpha3
kind: DestinationRule
metadata:
  name: istio-destination-rule1

spec:
  host: app-svc.prod.svc.cluster.local
  subsets:
  - name: app-service-subset          
    labels:                           
      app: app
      version: v2
      chapter: istio
      topic: traffic-management
    trafficPolicy:
      loadBalancer:
        simple: ROUND_ROBIN


>destination_rule_2 _

apiVersion: networking.istio.io/v1alpha3
kind: DestinationRule
metadata:
  name: istio-destination-rule2

spec:
  host: app2-svc.prod.svc.cluster.local
  subsets:
  - name: app2-service-subset
    labels:                           
      app: app2
      version: v2
      chapter: istio
      topic: traffic-management
    trafficPolicy:
      loadBalancer:
        simple: ROUND_ROBIN            


>flow
DNS--->Gateway--->Virtual Service--->service FQDN--->Destination Rule--->Labels--->pod/microservice


>above, we have gateway pod deployed in istio-system namespace , while our application mesh is in a prod
>namespace, and virtual service object is also applied to that gateway pod which is in istio-system name space.
>this is all handle by istiod, As long as selectors match, is not care about namespaces.


>using above Virtual service and gateway, access to the pod is only possible from outside of the cluster.
>to access the pods from within the cluster, we need to specify seperate VIRTUAL SERVICE with rules.

>curl -H "Host:<deep.com>" http://ec2ip:port


To enable to access the service from within the cluster, we defines the new virtual service :

>InterMesh Virtual Service

apiVersion: networking.istio.io/v1alpha3
kind: VirtualService
metadata:
  name: istio-virtual-svc

spec:
  hosts:
  - app-svc.prod.svc.cluster.local     

  http:
  - name: virtual-service-routes
    route:
    - destination:
        host: app-svc.prod.svc.cluster.local
        subset: app-service-subset         
      weight: 80                            

  - route:
    - destination:
        host: app2-svc.prod.svc.cluster.local
        subset: app2-service-subset         
      weight: 20 

>-------------------------------------------------------------------------------------------------------------
**************************************************************************************************************
>-------------------------------------------------------------------------------------------------------------        


#Service Entry _

>ref_ https://istio.io/v1.5/pt-br/docs/reference/config/networking/service-entry/#ServiceEntry-Location

>service entry is a firewall rule for istio and works ONLY FOR EGRESS TRAFFIC. i.e. it controls the outgoing 
>request. it is similar to the k8s network policy , but difference between is that, Service entry allow us to 
>have LAYER-7 firewall rules, Where we can mentioned the DNS/fqdn name insted of ip addresses and ports only.


>Envoy proxy allow all the traffic outside of service mesh to in, this is default behaviour. 
>however, this is not the ideal behaviour, ideally all traffic should be denied. this behaviour can be changed 
>in istio's config map, named istio.

>using service , we create a network policies or service entries , and we can apply this entries to the proxies.
>and as per the rules traffic can be allowed or denied.

>


apiVersion: networking.istio.io/v1alpha3
kind: ServiceEntry
metadata:
  name: external-svc-https
spec:
  hosts:
  - api.dropboxapi.com           #only to these hosts , egress traffic is allowed.
  - www.googleapi.com           #from inside of service mesh, application can access these webpages.
  - api.facebook.com
  - www.google.com
 # - "*.compute-1.amazonaws.com"       # using RE, RESOLUTION needed to be set to NONE.

  ports:                         #on these port on host, service is accessible. fqdn, ip:port combination
  - number: 443
    name: https
    protocol: TLS

  resolution: DNS                           #DNS, cuz, in host we gave fqdn

  location: MESH-EXTERNAL  #MESH-INTERNAL   #these iterates that, host are external, if they are not within mesh
                                            #it can be in different n/w or on different cluster or on-prem also.

>------------------------------------------------------------------------------------------------------------- 