>
>there are various ways to schedule a pod on node or select a Node to schedule/execute the pod,
>these are_
      1.Node Name and Node Selector
      2.Node Affinity and Node-Anti-Affinity
      3.Pod Affinity and Pod-Anti-Affinity
      4.Taints and Tolerations

>kubernetes user normally do not need to choose a node to execute their pod, Instead , selection of appropriate
>pod is automatically handled by kubernetes scheduler.

>k8s schedules watches for the newly created pod that have no Node assigned and for every such pod scheduler
>becomes responsible for finding the best node for that pod to run on.

>Automatic node scheduling prevents user from scheduling pod on unhealthy node.
>However, k8s provide the flexibility , to allow user to select the node, so that certain condition like RAM, SSD
>is fullfilled for execution of certain pod that need such specifications.


>-----------------------------------------------------------------------------------------------------------------

# Node Affinty and Node antiAffinity_

>ref_
>https://kubernetes.io/blog/2017/03/advanced-scheduling-in-kubernetes/
>https://kubernetes.io/docs/concepts/scheduling-eviction/assign-pod-node/
>https://kubernetes.io/docs/tasks/configure-pod-container/assign-pods-nodes-using-node-affinity/


>In Node Affinty and Node antiAffinity , Pod will be scheduled on the proper Node based on the rules defined under
>Node affinity and AntiAffinity rules in pod spec manifest file.
>i.e based the node affinity rules, Schedule will decides the node for the pod to get scheduled on.

Node Affinity_:

>Node affinity is conceptually similar to nodeSelector, allowing you to constrain which nodes your Pod can 
>be scheduled on based on node labels. However, it gives more flexibility to the user through the rules
>which we can defined. Instead of directaly giving node's name or label , we give condition based on which 
>scheduler select the node to schedule the pod. There are two types of node affinity rules/policies_

#requiredDuringSchedulingIgnoredDuringExecution: 
The scheduler can't schedule the Pod unless the rule is met / matching node is found. 
This functions like nodeSelector, but with a more expressive syntax.

#preferredDuringSchedulingIgnoredDuringExecution: 
The scheduler tries to find a node that meets the rule. If a matching node is not available, 
the scheduler still schedules the Pod.

>Note: In the preceding types, IgnoredDuringExecution means that if the node labels change after 
>Kubernetes schedules the Pod, the Pod continues to run.
>You can specify node affinities using the .spec.affinity.nodeAffinity field in your Pod spec.

For example, consider the following Pod spec_

apiVersion: v1
kind: Pod
metadata:
  name: with-node-affinity
spec:
  affinity:
    nodeAffinity:
      requiredDuringSchedulingIgnoredDuringExecution:
        nodeSelectorTerms:
        - matchExpressions:
          - key: topology.kubernetes.io/zone
            operator: In
            values:
            - antarctica-east1
            - antarctica-west1

      preferredDuringSchedulingIgnoredDuringExecution:
      - weight: 1
        preference:
          matchExpressions:
          - key: another-node-label-key
            operator: In
            values:
            - another-node-label-value
  containers:
  - name: with-node-affinity
    image: registry.k8s.io/pause:2.0


>In this example, the following rules apply:

The node must have a label with the key topology.kubernetes.io/zone and the value of that label 
must be either antarctica-east1 or antarctica-west1.

The node preferably has a label with the key another-node-label-key and 
the value another-node-label-value.

You can use the operator field to specify a logical operator for Kubernetes to use when 
interpreting the rules. You can use In, NotIn, Exists, DoesNotExist, Gt and Lt.


>NotIn and DoesNotExist allow you to define node anti-affinity behavior. 
>Alternatively, you can use node taints to repel Pods from specific nodes.



Note: (as per doc, ref_  https://kubernetes.io/docs/concepts/scheduling-eviction/assign-pod-node/)

>If you specify both nodeSelector and nodeAffinity, both must be satisfied for the Pod to be scheduled onto a node.

>If you specify multiple "nodeSelectorTerms" associated with nodeAffinity types, 
>then the Pod can be scheduled onto a node if one of the specified nodeSelectorTerms can be satisfied. (LOGICAL OR)

affinity:
    nodeAffinity:
      requiredDuringSchedulingIgnoredDuringExecution:

        nodeSelectorTerms:
        - matchExpressions:
          - key: topology.kubernetes.io/zone
            operator: In
            values:
            - antarctica-east1
            - antarctica-west1
                                  #OR
        nodeSelectorTerms:
        - matchExpressions:
          - key: topology.kubernetes.io/zone
            operator: In
            values:
            - ap-south-1
            - ap-south-2


*                                   *************************


>If you specify multiple "matchExpressions" associated with a single "nodeSelectorTerms", 
>then the Pod can be scheduled onto a node only if all the matchExpressions are satisfied. (LOGICAL AND)


affinity:
    nodeAffinity:
      requiredDuringSchedulingIgnoredDuringExecution:
        nodeSelectorTerms:

        - matchExpressions:
          - key: topology.kubernetes.io/zone
            operator: In
            values:
            - antarctica-east1
            - antarctica-west1
                                    #AND
        - matchExpressions:
          - key: topology.kubernetes.io/zone
            operator: In
            values:
            - ap-south-1
            - ap-south-2
              

>-----------------------------------------------------------------------------------------------------------------


Node affinity weight :

You can specify a weight between 1 and 100 for each instance of the 
>"preferredDuringSchedulingIgnoredDuringExecution" affinity type. 

When the scheduler finds nodes that meet all the other scheduling requirements of the Pod, 
the scheduler iterates through every preferred rule that the node satisfies and adds the 
value of the weight for that expression to a sum.

The final sum is added to the score of other priority functions for the node. 
Nodes with the highest total score are prioritized when the scheduler makes a scheduling decision for the Pod.


note: 
>If you specify multiple nodeSelectorTerms associated with nodeAffinity types, 
>then the Pod can be scheduled onto a node if one of the specified nodeSelectorTerms can be satisfied. (LOGICAL OR)

>If you specify multiple "matchExpressions" associated with a single "nodeSelectorTerms", 
>then the Pod can be scheduled onto a node only if all the matchExpressions are satisfied. (LOGICAL AND)


apiVersion: v1
kind: Pod
metadata:
  name: with-affinity-anti-affinity
spec:
  affinity:
    nodeAffinity:
      requiredDuringSchedulingIgnoredDuringExecution:
        nodeSelectorTerms:
        - matchExpressions:                      # nodeSelectorTerms:
          - key: kubernetes.io/os      #If you specify multiple nodeSelectorTerms associated with nodeAffinity types,
            operator: In               #then the Pod can be scheduled onto a node if one of the specified
            values:                    #nodeSelectorTerms can be satisfied. (LOGICAL OR)
            - linux
            
      preferredDuringSchedulingIgnoredDuringExecution:
      - weight: 1
        preference:                     #preference, only for iterating preferences, and determining the weight.
          matchExpressions:
          - key: label-1
            operator: In                   
            values:
            - key-1
                                 #AND
      - weight: 50
        preference:
          matchExpressions:
          - key: label-2
            operator: In
            values:
            - key-2
  containers:
  - name: with-node-affinity
    image: registry.k8s.io/pause:2.0

If there are two possible nodes that match the preferredDuringSchedulingIgnoredDuringExecution rule, 
one with the label-1:key-1 label and another with the label-2:key-2 label, the scheduler considers
the weight of each node and adds the weight to the other scores for that node, 
and schedules the Pod onto the node with the highest final score.

>Note: If you want Kubernetes to successfully schedule the Pods in this example, 
>you must have existing nodes with the kubernetes.io/os=linux label.

>-----------------------------------------------------------------------------------------------------------------


Node AntiAffinity_ :

In kubernetes, there is exclusive policy such as a Node AntiAffinity, However, it is possible to emulate 
the behaviour , which works opposite to Node Affinity rules.


>Operator value of, "NotIn" and "DoesNotExist" allow you to define node anti-affinity behavior. 
>Alternatively, you can use node taints to repel Pods from specific nodes.

affinity:
    nodeAffinity:
      requiredDuringSchedulingIgnoredDuringExecution:
        nodeSelectorTerms:
        - matchExpressions:
          - key: topology.kubernetes.io/zone
            operator: NotIn
            values:
            - antarctica-east1      #these are AZ's of the node in aws cloud.
            - antarctica-west1

>above rule specifies that, pod must NOT get schedule on the Node having key as topology.kubernetes.io/zone 
>In the AZ , having values as antarctica-east1 and antarctica-west1, Which emulates the Node-Anti-Affinity
>behaviour.


affinity:
    nodeAffinity:
      requiredDuringSchedulingIgnoredDuringExecution:
        nodeSelectorTerms:

        - matchExpressions:
          - key: topology.kubernetes.io/zone
            operator: DoesNotExist
            values:
            - antarctica-east1
            - antarctica-west1            


>above rule specifies that, Pod must NOT get schedule on the Node having key as topology.kubernetes.io/zone,
>in the AZ , that does not exist (key) in the values (az) as antarctica-east1 and antarctica-west1. 
i.e. 
>Any Node having key as topology.kubernetes.io/zone ,that DOES NOT EXIST in AZ having values as antarctica-east1 
>and antarctica-west1, pod will get schedule on that node. This emulates the anti Node Affinity behaviour.

>-----------------------------------------------------------------------------------------------------------------



