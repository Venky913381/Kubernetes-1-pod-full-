>
> Three types of volumes are :-> 
1> EmptyDir
2> HostPath
3> PersistantDisk

# 1.EMPTYDIR ( Creating volume inside pod, i.e. alongside container (EmptyDir) )

apiVersion: v1 
kind: Pod
metadata: 
  name: pod1 

spec:
  containers:
    - name: vol1 
      image: nginx 

      volumeMounts:
        - mountPath: /data 
          name: test-vol

  volumes:
    - name: test-vol
      emptyDir: {}        

>data will remain inside the pod and will be available only to the containers inside that pod.
>this data will not be available to other containers on other pods on same machine or other pods on other machines.

>emptyDir is a temporary storage and it have a lifecycle similar to the pod. i.e. once pod is deleted
>volume and data will also be lost.

>it is initially empty, emptydir volumes are stored on whatever medium is backing the node, that is
>it might be disk or n/w storage or RAM (emptyDir.medium feild to Memory)

>all containers in the pod can read and write to this volume by mounting the volume at some path in their
>file system.

>when pod is removed from node, data will be lost for ever, it is mainly used to store cache or temporary
>data to be processed.

>--------------------------------------------------------------------------------------------------------

# 2.HostPath ( Creating volume outside of pod, i.e. on Node machine. (HOstPath) )

>if we delete the POD, data will be preserved in directory in sync on Host Machine, 
>and when new POD is recreated by controller, all the data will be present in new POD inside the container.
.i.e.
>data volumes is created On the Host Machine storage, and will be available to all the PODs on that machine.

apiVersion: v1 
kind: Pod
metadata: 
  name: pod2

spec:
  containers:
    - name: vol1 
      image: nginx
      volumeMounts:
        - name: test-vol2           # on container
          mountPath: /data

  volumes:                 # volume on host machine
    - name: test-vol2                         #/data on container & /tmp/data on host, will be in sync.
      hostPath:
          path: /tmp/data    


>this type of volume mounts a File or Directory created on node where pod is running.

>hostpath directory referes to directory created on node where pod is running.

>use it with caution becouse when pod are schedule on multiple nodes , each node gets own hostPath 
>storage volume. these may not be in sync with each other and different pods might be using a different data.

>when node become unstable, the pod might fails to access the hostpath directory and eventually gets terminated.


>-------------------------------------------------------------------------------------------------------------

# EKS ON AWS  ( Persistance data , with cluster on the cloud)                             

>In above two cases , if pod is get schedule on any machine , other than its original machine in cluster data will 
>no longer be available to the pod.
>In this all we need a volume which is available to the all the machines in the cluster, 
>Here AWS EKS (cluster in cloud) comes to rescue_

>In this approch , we create a managed k8s cluster on aws eks, and create a ebs volume, which will remain
>available to the all nodes participating in the managed cloud cluster.  
(managed cluster .i.e. AWS ITSELF WILL MANAGED MASTER NODE/CONTROL PLANE)

>If pod get schedule on a perticular node, then EBS volume will get attached to that node automatically and
>if we delete and recreates the pod , on another machines in cluster, then that EBS volume will automatically get
>attached to that machine. and this way pod will always have access to the volume and the data.

>Create EKS cluster on K8s_
>1)install awscli
>2)with help of IAM user log in to aws account via aws-cli.
>3)start accessing aws services over awscli

#to create EKS cluster_
>eksctl create cluster --name <cluster-name> --node-type <type of ec2> --region <region> --node-zones <az>

>eksctl create cluster --name my-cluster --node-type t2.small --region ap-south-1 --node-zones ap-south-1a

apiVersion: v1
kind: Pod                                                 
metadata: 
  name: vol2
spec: 
  containers:                
    - name: container5          
      image: nginx
      imagePullPolicy: IfNotPresent
      
      volumeMounts:
        - mountPath: /data
          name: test-volume

  volumes:
    - name: test-volume
      awsElasticBlockStorage:                 # attach ebs volumes pod.
          volumeID: "vol-02c13c4470d26d461"
          fsType: ext4
      

>once our cluster get set up, it will also download the kube-config in to local machine. and we will 
>able to directaly use the kubectl commands on eks, No manual configuration is needed.

 
>-------------------------------------------------------------------------------------------------------------